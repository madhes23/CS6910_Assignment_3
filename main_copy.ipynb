{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from Utils import preprocess, string_to_tensor, plot_graphs\n",
    "from AkshrantarDataset import AksharantarDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'tam'\n",
    "start_token = '<'\n",
    "end_token = '>'\n",
    "pad_token = ' '\n",
    "unk_token = '~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = AksharantarDataset(language)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=data.tr_l2i[pad_token])\n",
    "\n",
    "target_dict_count = len(data.tr_l2i)\n",
    "english_dict_count = len(data.en_l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'aksharantar_sampled/' + language\n",
    "\n",
    "# train_df = pd.read_csv(path+'/'+language+'_train.csv', header=None)\n",
    "# test_df = pd.read_csv(path+'/'+language+'_test.csv', header=None)\n",
    "# val_df = pd.read_csv(path+'/'+language+'_valid.csv', header=None)\n",
    "\n",
    "# train_source, train_target = train_df[0].tolist(), train_df[1].tolist()\n",
    "# test_source, test_target = test_df[0].tolist(), test_df[1].tolist()\n",
    "# val_source, val_target = val_df[0].tolist(), val_df[1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_sample = 5\n",
    "for i in range(num_sample):\n",
    "    print(f'{train_source[i]}  -->  {train_target[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Charecters :  50\n",
      "Target Charecters: \n",
      "0 ய\t\n",
      "1 ற\t2 <\t3 ே\t4 ச\t5 உ\t\n",
      "6 ோ\t7 ை\t8 ு\t9 த\t10 ந\t\n",
      "11 ஸ\t12 ்\t13 ஒ\t14 ண\t15 ங\t\n",
      "16 ஞ\t17 ஈ\t18 ஊ\t19 வ\t20 ொ\t\n",
      "21 ஐ\t22 ௌ\t23 ள\t24 ழ\t25 ஷ\t\n",
      "26 ட\t27 ப\t28 ஃ\t29 >\t30 எ\t\n",
      "31 ஜ\t32 க\t33 ீ\t34 ல\t35 ூ\t\n",
      "36 இ\t37 ம\t38 ஆ\t39 ன\t40 அ\t\n",
      "41 ஏ\t42 ி\t43 ா\t44 ஹ\t45 ெ\t\n",
      "46 ர\t47 ஓ\t48 ~\t49  \t\n"
     ]
    }
   ],
   "source": [
    "# english_chars = list(set(''.join(train_source) + start_token + end_token + pad_token + unk_token))\n",
    "# target_chars = list(set(''.join(train_target) + start_token + end_token + pad_token + unk_token))\n",
    "\n",
    "# english_dict_count = len(english_chars)\n",
    "# target_dict_count = len(target_chars)\n",
    "\n",
    "# print(\"Number of Charecters : \", len(data.tr_l2i))\n",
    "\n",
    "# print(\"Target Charecters: \")\n",
    "# for i, c in enumerate(target_chars):\n",
    "#     print(i, c, end='\\t')\n",
    "#     if i % 5 == 0:\n",
    "#         print()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_i2l, en_l2i = {}, {}\n",
    "# tr_i2l, tr_l2i = {}, {}\n",
    "\n",
    "# for i, x in enumerate(english_chars):\n",
    "#     en_l2i[x] = i\n",
    "#     en_i2l[i] = x\n",
    "\n",
    "# for i, x in enumerate(target_chars):\n",
    "#     tr_l2i[x] = i\n",
    "#     tr_i2l[i] = x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def preprocess(strings, start_token, end_token, pad_token):\n",
    "    \"\"\"Adds start and end token and adds padding\"\"\"\n",
    "    res = []\n",
    "    max_len = len(max(strings, key=len))\n",
    "\n",
    "    for item in strings:\n",
    "        temp = start_token + item + end_token\n",
    "        temp = temp.ljust(max_len+2, pad_token) #2 is added, because we added start and end token to each word\n",
    "        res.append(temp)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def string_to_tensor(strings, l2i_dict, unk_token):\n",
    "    \"\"\"\n",
    "    replaces the chareceters of the sting with corrospong ix (by refering l2i_dict) and returns as int tensor\n",
    "    \"\"\"\n",
    "    res = torch.zeros(len(strings), len(strings[0]))\n",
    "    \n",
    "    for i in range(len(strings)):\n",
    "        for j in range(len(strings[i])):\n",
    "            if strings[i][j] not in l2i_dict :\n",
    "                res[i][j] = l2i_dict[unk_token]\n",
    "            else:\n",
    "                res[i][j] = l2i_dict[strings[i][j]]\n",
    "        \n",
    "    return res.type(torch.LongTensor)\n",
    "\n",
    "\n",
    "def plot_graphs(training_errors, validation_errors, training_accuracy, validation_accuracy):\n",
    "    \"\"\"\n",
    "    Plots a Error and Accuracy graphs for training and validation data over the epochs\n",
    "\n",
    "    Params:\n",
    "    -----\n",
    "    training_errors: list containing error (ie loss values) of the training data over the epochs\n",
    "    validation_errors: list containing error (ie loss values) of the validation data over the epochs\n",
    "    training_accuracy: list containing accuracy of the training data over the epochs\n",
    "    validation_accuracy: list containing accuracy of the validation data over the epochs\n",
    "\n",
    "    Returns:\n",
    "    -----\n",
    "    fig: matplot figure object \n",
    "    \"\"\"\n",
    "    x = np.arange(len(training_errors))\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(x, training_errors, label = \"Training Error\")\n",
    "    ax1.plot(x, validation_errors, label = \"Validation Error\")\n",
    "    ax1.set_title(\"Errors\")\n",
    "    ax1.legend(fontsize= 'small', loc='upper right')\n",
    "    ax2.plot(x, training_accuracy, label = \"Training Accuracy\")\n",
    "    ax2.plot(x, validation_accuracy, label = \"Validation Accuracy\")\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax2.legend(fontsize = 'small',loc='upper right')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_source_tensor = string_to_tensor(preprocess(val_source, start_token, end_token, pad_token), en_l2i, unk_token).transpose(0,1).requires_grad_(False)\n",
    "# val_target_tensor = string_to_tensor(preprocess(val_target, start_token, end_token, pad_token), tr_l2i, unk_token).transpose(0,1).requires_grad_(False)\n",
    "\n",
    "# test_source_tensor = string_to_tensor(preprocess(test_source, start_token, end_token, pad_token), en_l2i, unk_token).transpose(0,1).requires_grad_(False)\n",
    "# test_target_tensor = string_to_tensor(preprocess(test_target, start_token, end_token, pad_token), tr_l2i, unk_token).transpose(0,1).requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers = 1, p = 0, bi_dir = False, rnn_class = nn.GRU):\n",
    "        \"\"\"\n",
    "        Init Parameters:\n",
    "        input_size : english_dict_count\n",
    "        embedding_size : size of each embedding vector\n",
    "        hidden_size : size of hidden state vector\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "        rnn_class: type of RNN to be used in the encoder\n",
    "\n",
    "        Input:\n",
    "        x : torch.Tensor of shape (seq_length, N)\n",
    "            where seq_length - len of longest string in the batch\n",
    "            N - batch size\n",
    "        \n",
    "        Outpus:\n",
    "        outputs: torch.Tensor of shape (seq_len, N, hidden_size * D), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size) if(rnn_class == \"LSTM\")\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn_class= rnn_class\n",
    "        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            outputs, (hidden, cell) = self.rnn(embedding)\n",
    "            # outputs shape: (seq_length, N, hidden_size)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedding)\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            return outputs, hidden, cell\n",
    "        else:\n",
    "            return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers = 1, p = 0, bi_dir = False, rnn_class = nn.GRU):\n",
    "        \"\"\"input size = output size = target language charecters\n",
    "        Init Parameters:\n",
    "        input_size: target_dict_count\n",
    "        embedding_size: size of each embedding vector\n",
    "        hidden_size: size of hidden state vector\n",
    "        output_size: number of output features in fully connected layer\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "        rnn_class: type of RNN to be used in the encoder\n",
    "\n",
    "        Input:\n",
    "        x: torch.Tensor of shape (N)\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "\n",
    "        Outputs:\n",
    "        predications: torch.Tensor of shape (N, target_dict_count), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size) if(rnn_class == \"LSTM\")\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn_class = rnn_class\n",
    "        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "        self.D = 1\n",
    "        if(bi_dir == True):\n",
    "            self.D = 2\n",
    "        self.fc = nn.Linear(hidden_size * self.D, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, cell = None):\n",
    "        #cell is set to none, for GRU and RNN\n",
    "\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        # print(x.shape, hidden.shape, cell.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "            # outputs shape: (1, N, hidden_size * D)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedding, hidden)\n",
    "            \n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            return predictions, hidden, cell\n",
    "        else:\n",
    "            return predictions, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        encoder_layers = encoder.num_layers\n",
    "        decoder_layers = decoder.num_layers\n",
    "        D = decoder.D #we set bidiretion as common in both encoder and decoder, so no need to check for D value seperately\n",
    "        self.enc_to_dec = nn.Linear(encoder_layers*D, decoder_layers*D)\n",
    "        self.rnn_class = decoder.rnn_class #we use same rnn in both encoder and decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0):\n",
    "        \"\"\"source : (source_len, N) - not sure\n",
    "        teacher_forching_ratio : probability in which original values is favored over predicted values\n",
    "                                if 0 : predicted values is passed for all chars in target\n",
    "                                if 1 : true values is passed for all chars in target\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size = source.shape[1] \n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = target_dict_count\n",
    "\n",
    "        # print(\"source shape \", source.shape)\n",
    "        # print(\"target shape \", target.shape)\n",
    "        # print(\"N : \", batch_size)\n",
    "        # print(\"tar len : \", target_len)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "        # print(\"outputs shape : \", outputs.shape)\n",
    "\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            _, hidden, cell = self.encoder(source)\n",
    "        else:\n",
    "            _, hidden = self.encoder(source)\n",
    "\n",
    "        N = hidden.shape[1]\n",
    "        hidden_size= hidden.shape[2]\n",
    "        # hidden, cell shape: (D*encoder_layers, N, hidden_size)\n",
    "\n",
    "        hidden = hidden.transpose(0, 2) # hidden shape: (hidden_size, N, D*encoder_layers)\n",
    "        hidden = hidden.reshape(-1, hidden.shape[2]) # hidden shape: (hidden_size * N, D*encoder_layers)\n",
    "        hidden = self.enc_to_dec(hidden) # hidden shape: (hidden_size * N, D*decoder_layers)\n",
    "        hidden = hidden.reshape(hidden_size, N, hidden.shape[1]) # hidden shape: (hidden_size, N, D*decoder_layers)\n",
    "        hidden = hidden.transpose(0,2) # hidden shape: (D*decoder_layers, N, hidden_size)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            #at all the below steps, cell will have the shape of hidden\n",
    "            cell = cell.transpose(0,2)\n",
    "            cell = cell.reshape(-1, cell.shape[2])\n",
    "            cell = self.enc_to_dec(cell)\n",
    "            cell = cell.reshape(hidden_size, N, cell.shape[1])\n",
    "            cell = cell.transpose(0,2)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "        outputs[:, :, data.tr_l2i[start_token]] = 1 #setting prob = 1 for starting token \n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "                output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = self.decoder(x, hidden)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        # print(\"OUTPUTS: \", outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def calc_accuracy(self, output, target):\n",
    "        \"\"\"\n",
    "        output: torch.Tensor of shape (seq_len, N)\n",
    "        target: torch.Tensor of shape (seq_len, N)\n",
    "        \"\"\"\n",
    "        # batch_size = 32\n",
    "        running_acc = 0\n",
    "        seq_len = output.shape[0]\n",
    "        N = output.shape[1]\n",
    "        matched_strings = 0\n",
    "        with torch.no_grad():\n",
    "            for j in range(N):\n",
    "                current_word_matched = True\n",
    "                for i in range(seq_len):\n",
    "                    if(target[i][j] in {data.tr_l2i[pad_token]}): #we dont care whatever prediction in the pad_token place\n",
    "                        continue\n",
    "                    if(output[i][j] != target[i][j]): #compare the predictions of charecters, start and end_token places\n",
    "                        current_word_matched = False\n",
    "                        break\n",
    "                if(current_word_matched == True):\n",
    "                    matched_strings += 1\n",
    "        return matched_strings*100 / N \n",
    "\n",
    "\n",
    "    def calc_evaluation_metrics(self, soruce_strings, target_strings):\n",
    "        \"\"\"\n",
    "\n",
    "        Returns:\n",
    "        loss: loss value for the current batch of strings\n",
    "        accuracy: accuracy value for the current batch of strings\n",
    "        \"\"\"\n",
    "        batch_size = 32\n",
    "        loss  = 0\n",
    "        with torch.no_grad():\n",
    "            no_of_batch = 0\n",
    "            running_accuracy = 0\n",
    "            for i in range(0, len(soruce_strings), batch_size):\n",
    "                inp_data = string_to_tensor(preprocess(soruce_strings[i:i+batch_size], start_token, end_token, pad_token), data.en_l2i, unk_token).transpose(0,1)\n",
    "                target = string_to_tensor(preprocess(target_strings[i:i+batch_size], start_token, end_token, pad_token), data.tr_l2i, unk_token).transpose(0,1)\n",
    "\n",
    "                output = self(inp_data, target)\n",
    "                running_accuracy += self.calc_accuracy(output.argmax(2), target)\n",
    "\n",
    "                output = output.reshape(-1, output.shape[2])\n",
    "                target = target.reshape(-1)\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                loss += loss.item()\n",
    "                no_of_batch += 1\n",
    "        return loss, running_accuracy/no_of_batch\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 30\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = english_dict_count\n",
    "input_size_decoder = target_dict_count\n",
    "output_size = target_dict_count\n",
    "embedding_size = 32\n",
    "encoder_layers = 2\n",
    "decoder_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "hidden_size = 64\n",
    "bi_directional = True\n",
    "rnn = nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(english_dict_count, embedding_size, hidden_size, \n",
    "              num_layers=encoder_layers, \n",
    "              bi_dir=bi_directional,\n",
    "              p=enc_dropout,\n",
    "              rnn_class=rnn)\n",
    "dec = Decoder(target_dict_count, embedding_size, hidden_size, target_dict_count, \n",
    "              num_layers=decoder_layers, \n",
    "              bi_dir=bi_directional, \n",
    "              p = dec_dropout,\n",
    "              rnn_class=rnn)\n",
    "\n",
    "mod = Seq2Seq(enc, dec)\n",
    "\n",
    "optimizer = optim.Adam(mod.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_print(output):\n",
    "    \"\"\"output shape: target_seq_length * N\"\"\"\n",
    "    res = []\n",
    "    for j in range(output.shape[1]):\n",
    "        temp = \"\"\n",
    "        for i in range(output.shape[0]):\n",
    "            temp += tr_i2l[output[i,j].item()]\n",
    "        \n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1/30] \t Loss: 1.411\t Acc: 0.01 \t Val Loss: 3.695\t Val Acc: 0.12\n",
      "[Epoch   2/30] \t Loss: 0.936\t Acc: 0.09 \t Val Loss: 2.878\t Val Acc: 0.24\n",
      "[Epoch   3/30] \t Loss: 0.843\t Acc: 0.19 \t Val Loss: 2.932\t Val Acc: 0.46\n",
      "[Epoch   4/30] \t Loss: 0.805\t Acc: 0.23 \t Val Loss: 2.293\t Val Acc: 0.46\n",
      "[Epoch   5/30] \t Loss: 0.790\t Acc: 0.32 \t Val Loss: 2.235\t Val Acc: 0.68\n",
      "[Epoch   6/30] \t Loss: 0.783\t Acc: 0.44 \t Val Loss: 2.209\t Val Acc: 0.59\n",
      "[Epoch   7/30] \t Loss: 0.784\t Acc: 0.42 \t Val Loss: 2.423\t Val Acc: 0.61\n",
      "[Epoch   8/30] \t Loss: 0.795\t Acc: 0.42 \t Val Loss: 2.111\t Val Acc: 0.49\n",
      "[Epoch   9/30] \t Loss: 0.801\t Acc: 0.48 \t Val Loss: 1.951\t Val Acc: 0.34\n",
      "[Epoch  10/30] \t Loss: 0.808\t Acc: 0.46 \t Val Loss: 1.857\t Val Acc: 0.49\n",
      "Epoch  11 | Batches: 650 / 1600\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Education\\IITM\\Second Sem\\DL\\3\\main_copy.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Education/IITM/Second%20Sem/DL/3/main_copy.ipynb#X32sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Education/IITM/Second%20Sem/DL/3/main_copy.ipynb#X32sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Back prop\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Education/IITM/Second%20Sem/DL/3/main_copy.ipynb#X32sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Education/IITM/Second%20Sem/DL/3/main_copy.ipynb#X32sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(mod\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Education/IITM/Second%20Sem/DL/3/main_copy.ipynb#X32sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\madhe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\madhe\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list, acc_list, val_loss_list, val_acc_list = [], [], [], []\n",
    "\n",
    "init_teacher_forcing_ratio = 0.8\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    cur_batch = 0\n",
    "    running_accuracy = 0\n",
    "    total_batches = math.ceil(len(train_source)/batch_size)\n",
    "    for i in range(0, len(train_source), batch_size):\n",
    "        src_strings = train_source[i: i+batch_size]\n",
    "        tar_strings = train_target[i: i+batch_size]\n",
    "\n",
    "        src_strings = preprocess(src_strings, start_token, end_token, pad_token)\n",
    "        tar_strings = preprocess(tar_strings, start_token, end_token, pad_token)\n",
    "\n",
    "        #transposing to make the shape as expected\n",
    "        inp_data = string_to_tensor(src_strings, en_l2i, unk_token).transpose(0,1)\n",
    "        target = string_to_tensor(tar_strings, tr_l2i, unk_token).transpose(0,1)\n",
    "\n",
    "        #here teacher forcing ratio will reduces linearly from init_teacher_forcing_ratio to 0 in half the number of epochs\n",
    "        teacher_forcing_ratio = max(0, init_teacher_forcing_ratio * (1 - (epoch*2/num_epochs)))\n",
    "        output = mod(inp_data, target, teacher_forcing_ratio)\n",
    "\n",
    "        running_accuracy += mod.calc_accuracy(output.argmax(2), target)\n",
    "\n",
    "        # print(\"train: output : \", output.shape)\n",
    "        if(epoch in {math.floor(0.8 * num_epochs), num_epochs-1}):\n",
    "            result = temp_print(output.argmax(2))\n",
    "            print(\"result: \", result)\n",
    "            print(\"target: \", tar_strings)\n",
    "        \n",
    "        # print(\"output: \",result)\n",
    "        # print(\"target:\", tar_strings)\n",
    "\n",
    "        # print(\"op before reshopsed \", output.shape)\n",
    "        # print(\"tar before reshape: \", target.shape)\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "\n",
    "        # print(\"op: \", output.shape)\n",
    "        # print(\"tar: \", target.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mod.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        cur_batch += 1        \n",
    "        \n",
    "        #comment this line when running with a log file (or in kaggle)\n",
    "        print(f\"Epoch {epoch+1:3d} | Batches: {cur_batch} / {total_batches}\", end='\\r')\n",
    "\n",
    "    # val_output = mod(val_source_tensor, val_target_tensor)\n",
    "    # val_output = val_output.reshape(-1, val_output.shape[2])\n",
    "    # val_target_tensor = val_target_tensor.reshape(-1)\n",
    "    # # print(f\"val output : {val_output.shape} \\t val_target: {val_target_tensor.shape}\")\n",
    "    # val_loss = criterion(val_output, val_target_tensor)\n",
    "\n",
    "    val_loss, val_accuracy= mod.calc_evaluation_metrics(val_source, val_target)\n",
    "    # val_loss = 0\n",
    "\n",
    "\n",
    "    print(f\"[Epoch {epoch+1:3d}/{num_epochs}] \\t Loss: {(running_loss/total_batches):.3f}\\t Acc: {(running_accuracy/total_batches):2.2f} \\t Val Loss: {val_loss:2.3f}\\t Val Acc: {val_accuracy:2.2f}\")\n",
    "    loss_list.append(running_loss/total_batches)\n",
    "    acc_list.append(running_accuracy/total_batches)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_accuracy)\n",
    "\n",
    "fig = plot_graphs(loss_list, val_loss_list, acc_list, val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  ['<வசிப்படத்திிலும்>>', '<இசைக்கின்றனர்>>>>>', '<ரஷிதாவும்>>>்>>>>>', '<அக்கானிகளை>>>>>>>>', '<கூப்பெட்டாங்க>>>>>', '<வருசத்திலிருந்து>்', '<ஸ்விரே>>>>>>>>>>>்', '<சிப்போராலோடும்>>>>', '<நாடகீயம்>>>>>>>>>>', '<வழித்த>>>>>>>>>>>>', '<கயானியிடம்>>>>>>>்', '<கடுஷு>>>>>>>>>>>>>', '<மலைக்கூட்டத்தில்>>', '<மிருகளிதையை>>>>>>>', '<மாபெரும்வேற்றியை>>', '<திருவிளனரகளள்>>>>>', '<தெரியவன்ததல்த>>>>>', '<வங்கிகளாலும்>>>>>>', '<நம்னாவிடில்>>>>>>>', '<நட்புபார்ப்புவார்>']\n",
      "target:  ['<வசிப்பிடத்திலும்> ', '<இசைக்கின்றனர்>    ', '<ரஷிதாவும்>        ', '<அக்காணிகளை>       ', '<கூப்பிட்டாங்க>    ', '<வருசத்திலிருந்து> ', '<ஸ்வைர்>           ', '<சிப்போராளோடும்>   ', '<நாடகீயம்>         ', '<வஹித்த>           ', '<கயானியிடம்>       ', '<கடுசு>            ', '<மலைக்கூட்டத்தில்> ', '<மிருகவதையை>       ', '<மாபெரும்வெற்றியை> ', '<திருவிளநகரில்>    ', '<தெரியவந்தால்தான்> ', '<வங்கிகளாலும்>     ', '<நம்பாவிடில்>      ', '<நட்புபாராட்டுபவர்>']\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "batch_size = 20\n",
    "\n",
    "src_strings = train_source[i: i+batch_size]\n",
    "tar_strings = train_target[i: i+batch_size]\n",
    "\n",
    "src_strings = preprocess(src_strings, start_token, end_token, pad_token)\n",
    "tar_strings = preprocess(tar_strings, start_token, end_token, pad_token)\n",
    "\n",
    "#transposing to make the shape as expected\n",
    "inp_data = string_to_tensor(src_strings, en_l2i, unk_token).transpose(0,1)\n",
    "target = string_to_tensor(tar_strings, tr_l2i, unk_token).transpose(0,1)\n",
    "\n",
    "#here teacher forcing ratio will reduces linearly from init_teacher_forcing_ratio to 0 in half the number of epochs\n",
    "teacher_forcing_ratio = max(0, init_teacher_forcing_ratio * (1 - (epoch*2/num_epochs)))\n",
    "output = mod(inp_data, target, teacher_forcing_ratio)\n",
    "\n",
    "result = temp_print(output.argmax(2))\n",
    "print(\"result: \", result)\n",
    "print(\"target: \", tar_strings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
