{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import preprocess, string_to_tensor\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'tam'\n",
    "start_token = '<'\n",
    "end_token = '>'\n",
    "pad_token = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'aksharantar_sampled/' + language\n",
    "\n",
    "train_df = pd.read_csv(path+'/'+language+'_train.csv', header=None)\n",
    "test_df = pd.read_csv(path+'/'+language+'_test.csv', header=None)\n",
    "val_df = pd.read_csv(path+'/'+language+'_valid.csv', header=None)\n",
    "\n",
    "train_source, train_target = train_df[0].tolist(), train_df[1].tolist()\n",
    "test_source, test_target = test_df[0].tolist(), test_df[1].tolist()\n",
    "val_source, val_target = val_df[0].tolist(), val_df[1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thottacharya  -->  தொட்டாச்சார்ய\n",
      "menmaithaan  -->  மென்மைதான்\n",
      "avarantri  -->  அவரன்றி\n",
      "mudiyarathu  -->  முடியறது\n",
      "aadaiyanigalaal  -->  ஆடையணிகளால்\n"
     ]
    }
   ],
   "source": [
    "num_sample = 5\n",
    "for i in range(num_sample):\n",
    "    print(f'{train_source[i]}  -->  {train_target[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Charecters :  49\n",
      "Target Charecters: \n",
      "0  \t\n",
      "1 ழ\t2 ச\t3 ு\t4 ஷ\t5 ஓ\t\n",
      "6 ெ\t7 ள\t8 ூ\t9 உ\t10 ர\t\n",
      "11 ஞ\t12 ஈ\t13 >\t14 <\t15 ய\t\n",
      "16 இ\t17 ா\t18 ந\t19 ஐ\t20 ொ\t\n",
      "21 ஃ\t22 ோ\t23 எ\t24 ங\t25 ஏ\t\n",
      "26 ஸ\t27 ஆ\t28 ல\t29 ண\t30 வ\t\n",
      "31 ன\t32 ை\t33 க\t34 ஒ\t35 ஜ\t\n",
      "36 ௌ\t37 ஊ\t38 த\t39 ற\t40 ்\t\n",
      "41 ி\t42 ீ\t43 ஹ\t44 ப\t45 ம\t\n",
      "46 ட\t47 அ\t48 ே\t"
     ]
    }
   ],
   "source": [
    "english_chars = list(set(''.join(train_source) + start_token + end_token + pad_token))\n",
    "target_chars = list(set(''.join(train_target) + start_token + end_token + pad_token))\n",
    "\n",
    "english_dict_count = len(english_chars)\n",
    "target_dict_count = len(target_chars)\n",
    "\n",
    "print(\"Number of Charecters : \", target_dict_count)\n",
    "\n",
    "print(\"Target Charecters: \")\n",
    "for i, c in enumerate(target_chars):\n",
    "    print(i, c, end='\\t')\n",
    "    if i % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_i2l, en_l2i = {}, {}\n",
    "tr_i2l, tr_l2i = {}, {}\n",
    "\n",
    "for i, x in enumerate(english_chars):\n",
    "    en_l2i[x] = i\n",
    "    en_i2l[i] = x\n",
    "\n",
    "for i, x in enumerate(target_chars):\n",
    "    tr_l2i[x] = i\n",
    "    tr_i2l[i] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_source_tensor = string_to_tensor(preprocess(val_source, start_token, end_token, pad_token), en_l2i).transpose(0,1).requires_grad_(False)\n",
    "val_target_tensor = string_to_tensor(preprocess(val_target, start_token, end_token, pad_token), tr_l2i).transpose(0,1).requires_grad_(False)\n",
    "\n",
    "test_source_tensor = string_to_tensor(preprocess(test_source, start_token, end_token, pad_token), en_l2i).transpose(0,1).requires_grad_(False)\n",
    "test_target_tensor = string_to_tensor(preprocess(test_target, start_token, end_token, pad_token), tr_l2i).transpose(0,1).requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers = 1, p = 0, bi_dir = False, rnn_class = nn.GRU):\n",
    "        \"\"\"\n",
    "        Init Parameters:\n",
    "        input_size : english_dict_count\n",
    "        embedding_size : size of each embedding vector\n",
    "        hidden_size : size of hidden state vector\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "        rnn_class: type of RNN to be used in the encoder\n",
    "\n",
    "        Input:\n",
    "        x : torch.Tensor of shape (seq_length, N)\n",
    "            where seq_length - len of longest string in the batch\n",
    "            N - batch size\n",
    "        \n",
    "        Outpus:\n",
    "        outputs: torch.Tensor of shape (seq_len, N, hidden_size * D), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size) if(rnn_class == \"LSTM\")\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn_class= rnn_class\n",
    "        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            outputs, (hidden, cell) = self.rnn(embedding)\n",
    "            # outputs shape: (seq_length, N, hidden_size)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedding)\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            return outputs, hidden, cell\n",
    "        else:\n",
    "            return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers = 1, p = 0, bi_dir = False, rnn_class = nn.GRU):\n",
    "        \"\"\"input size = output size = target language charecters\n",
    "        Init Parameters:\n",
    "        input_size: target_dict_count\n",
    "        embedding_size: size of each embedding vector\n",
    "        hidden_size: size of hidden state vector\n",
    "        output_size: number of output features in fully connected layer\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "        rnn_class: type of RNN to be used in the encoder\n",
    "\n",
    "        Input:\n",
    "        x: torch.Tensor of shape (N)\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "\n",
    "        Outputs:\n",
    "        predications: torch.Tensor of shape (N, target_dict_count), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size) if(rnn_class == \"LSTM\")\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn_class = rnn_class\n",
    "        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "        self.D = 1\n",
    "        if(bi_dir == True):\n",
    "            self.D = 2\n",
    "        self.fc = nn.Linear(hidden_size * self.D, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, cell = None):\n",
    "        #cell is set to none, for GRU and RNN\n",
    "\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        # print(x.shape, hidden.shape, cell.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "            # outputs shape: (1, N, hidden_size * D)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedding, hidden)\n",
    "            \n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            return predictions, hidden, cell\n",
    "        else:\n",
    "            return predictions, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        encoder_layers = encoder.num_layers\n",
    "        decoder_layers = decoder.num_layers\n",
    "        D = decoder.D #we set bidiretion as common in both encoder and decoder, so no need to check for D value seperately\n",
    "        self.enc_to_dec = nn.Linear(encoder_layers*D, decoder_layers*D)\n",
    "        self.rnn_class = decoder.rnn_class #we use same rnn in both encoder and decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        \"\"\"source : (source_len, N) - not sure\n",
    "        \"\"\"\n",
    "        batch_size = source.shape[1] \n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = target_dict_count\n",
    "\n",
    "        # print(\"source shape \", source.shape)\n",
    "        # print(\"target shape \", target.shape)\n",
    "        # print(\"N : \", batch_size)\n",
    "        # print(\"tar len : \", target_len)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "        # print(\"outputs shape : \", outputs.shape)\n",
    "\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            _, hidden, cell = self.encoder(source)\n",
    "        else:\n",
    "            _, hidden = self.encoder(source)\n",
    "\n",
    "        N = hidden.shape[1]\n",
    "        hidden_size= hidden.shape[2]\n",
    "        # hidden, cell shape: (D*encoder_layers, N, hidden_size)\n",
    "\n",
    "        hidden = hidden.transpose(0, 2) # hidden shape: (hidden_size, N, D*encoder_layers)\n",
    "        hidden = hidden.reshape(-1, hidden.shape[2]) # hidden shape: (hidden_size * N, D*encoder_layers)\n",
    "        hidden = self.enc_to_dec(hidden) # hidden shape: (hidden_size * N, D*decoder_layers)\n",
    "        hidden = hidden.reshape(hidden_size, N, hidden.shape[1]) # hidden shape: (hidden_size, N, D*decoder_layers)\n",
    "        hidden = hidden.transpose(0,2) # hidden shape: (D*decoder_layers, N, hidden_size)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            #at all the below steps, cell will have the shape of hidden\n",
    "            cell = cell.transpose(0,2)\n",
    "            cell = cell.reshape(-1, cell.shape[2])\n",
    "            cell = self.enc_to_dec(cell)\n",
    "            cell = cell.reshape(hidden_size, N, cell.shape[1])\n",
    "            cell = cell.transpose(0,2)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "        outputs[:, :, tr_l2i[start_token]] = 1 #setting prob = 1 for starting token \n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "                output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = self.decoder(x, hidden)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        # print(\"OUTPUTS: \", outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def calc_evaluation_loss(self, soruce_strings, target_strings, batch_size = 32):\n",
    "        running_loss  = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(soruce_strings), batch_size):\n",
    "                inp_data = string_to_tensor(preprocess(soruce_strings[i:i+batch_size], start_token, end_token, pad_token), en_l2i).transpose(0,1)\n",
    "                target = string_to_tensor(preprocess(target_strings[i:i+batch_size], start_token, end_token, pad_token), tr_l2i).transpose(0,1)\n",
    "\n",
    "                output = self(inp_data, target)\n",
    "                output = output.reshape(-1, output.shape[2])\n",
    "                target = target.reshape(-1)\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 2\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = english_dict_count\n",
    "input_size_decoder = target_dict_count\n",
    "output_size = target_dict_count\n",
    "encoder_embedding_size = 10\n",
    "decoder_embedding_size = 10\n",
    "encoder_layers = 1\n",
    "decoder_layers = 1\n",
    "enc_dropout = 0\n",
    "dec_dropout = 0\n",
    "embedding_size= 16\n",
    "hidden_size = 10\n",
    "bi_directional = False\n",
    "rnn = nn.RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(english_dict_count, embedding_size, hidden_size, num_layers=encoder_layers, bi_dir=bi_directional, rnn_class=rnn)\n",
    "dec = Decoder(target_dict_count, embedding_size, hidden_size, target_dict_count, num_layers=decoder_layers, bi_dir=bi_directional, rnn_class=rnn)\n",
    "\n",
    "mod = Seq2Seq(enc, dec)\n",
    "\n",
    "optimizer = optim.Adam(mod.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_print(output):\n",
    "    \"\"\"output shape: target_seq_length * N\"\"\"\n",
    "    res = []\n",
    "    for j in range(output.shape[1]):\n",
    "        temp = \"\"\n",
    "        for i in range(output.shape[0]):\n",
    "            temp += tr_i2l[output[i,j].item()]\n",
    "        \n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    no_of_batch = 0\n",
    "    for i in range(0, len(train_source[:2]), batch_size):\n",
    "        src_strings = train_source[i: i+batch_size]\n",
    "        tar_strings = train_target[i: i+batch_size]\n",
    "\n",
    "        src_strings = preprocess(src_strings, start_token, end_token, pad_token)\n",
    "        tar_strings = preprocess(tar_strings, start_token, end_token, pad_token)\n",
    "\n",
    "        #transposing to make the shape as expected\n",
    "        inp_data = string_to_tensor(src_strings, en_l2i).transpose(0,1)\n",
    "        target = string_to_tensor(tar_strings, tr_l2i).transpose(0,1)\n",
    "\n",
    "\n",
    "        output = mod(inp_data, target)\n",
    "        # print(\"train: output : \", output.shape)\n",
    "        # result = temp_print(output.argmax(2))\n",
    "        # print(\"result: \", result)\n",
    "        # print(\"target: \", tar_strings)\n",
    "        \n",
    "        # print(\"output: \",result)\n",
    "        # print(\"target:\", tar_strings)\n",
    "\n",
    "        # print(\"op before reshopsed \", output.shape)\n",
    "        # print(\"tar before reshape: \", target.shape)\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "\n",
    "        # print(\"op: \", output.shape)\n",
    "        # print(\"tar: \", target.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mod.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        no_of_batch += 1        \n",
    "\n",
    "    # val_output = mod(val_source_tensor, val_target_tensor)\n",
    "    # val_output = val_output.reshape(-1, val_output.shape[2])\n",
    "    # val_target_tensor = val_target_tensor.reshape(-1)\n",
    "    # # print(f\"val output : {val_output.shape} \\t val_target: {val_target_tensor.shape}\")\n",
    "    # val_loss = criterion(val_output, val_target_tensor)\n",
    "\n",
    "    val_loss= mod.calc_evaluation_loss(val_source[:2], val_target[:2])\n",
    "    # val_loss = 0\n",
    "    \n",
    "    print(f\"[Epoch {epoch+1:3d} / {num_epochs}] \\t Loss: {(running_loss/no_of_batch):.4f} \\t Val Loss: {val_loss:2.4f}\")\n",
    "    loss_list.append(running_loss/no_of_batch)\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
