{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import preprocess, string_to_tensor\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'tam'\n",
    "start_token = '<'\n",
    "end_token = '>'\n",
    "pad_token = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'aksharantar_sampled/' + language\n",
    "\n",
    "train_df = pd.read_csv(path+'/'+language+'_train.csv', header=None)\n",
    "test_df = pd.read_csv(path+'/'+language+'_test.csv', header=None)\n",
    "val_df = pd.read_csv(path+'/'+language+'_valid.csv', header=None)\n",
    "\n",
    "train_source, train_target = train_df[0].tolist(), train_df[1].tolist()\n",
    "test_source, test_target = test_df[0].tolist(), test_df[1].tolist()\n",
    "val_source, val_target = val_df[0].tolist(), val_df[1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thottacharya  -->  தொட்டாச்சார்ய\n",
      "menmaithaan  -->  மென்மைதான்\n",
      "avarantri  -->  அவரன்றி\n",
      "mudiyarathu  -->  முடியறது\n",
      "aadaiyanigalaal  -->  ஆடையணிகளால்\n"
     ]
    }
   ],
   "source": [
    "num_sample = 5\n",
    "for i in range(num_sample):\n",
    "    print(f'{train_source[i]}  -->  {train_target[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Charecters :  49\n",
      "Target Charecters: \n",
      "0  \t\n",
      "1 ழ\t2 ச\t3 ு\t4 ஷ\t5 ஓ\t\n",
      "6 ெ\t7 ள\t8 ூ\t9 உ\t10 ர\t\n",
      "11 ஞ\t12 ஈ\t13 >\t14 <\t15 ய\t\n",
      "16 இ\t17 ா\t18 ந\t19 ஐ\t20 ொ\t\n",
      "21 ஃ\t22 ோ\t23 எ\t24 ங\t25 ஏ\t\n",
      "26 ஸ\t27 ஆ\t28 ல\t29 ண\t30 வ\t\n",
      "31 ன\t32 ை\t33 க\t34 ஒ\t35 ஜ\t\n",
      "36 ௌ\t37 ஊ\t38 த\t39 ற\t40 ்\t\n",
      "41 ி\t42 ீ\t43 ஹ\t44 ப\t45 ம\t\n",
      "46 ட\t47 அ\t48 ே\t"
     ]
    }
   ],
   "source": [
    "english_chars = list(set(''.join(train_source) + start_token + end_token + pad_token))\n",
    "target_chars = list(set(''.join(train_target) + start_token + end_token + pad_token))\n",
    "\n",
    "english_dict_count = len(english_chars)\n",
    "target_dict_count = len(target_chars)\n",
    "\n",
    "print(\"Number of Charecters : \", target_dict_count)\n",
    "\n",
    "print(\"Target Charecters: \")\n",
    "for i, c in enumerate(target_chars):\n",
    "    print(i, c, end='\\t')\n",
    "    if i % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_i2l, en_l2i = {}, {}\n",
    "tr_i2l, tr_l2i = {}, {}\n",
    "\n",
    "for i, x in enumerate(english_chars):\n",
    "    en_l2i[x] = i\n",
    "    en_i2l[i] = x\n",
    "\n",
    "for i, x in enumerate(target_chars):\n",
    "    tr_l2i[x] = i\n",
    "    tr_i2l[i] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_source_tensor = string_to_tensor(preprocess(val_source, start_token, end_token, pad_token), en_l2i).transpose(0,1).requires_grad_(False)\n",
    "val_target_tensor = string_to_tensor(preprocess(val_target, start_token, end_token, pad_token), tr_l2i).transpose(0,1).requires_grad_(False)\n",
    "\n",
    "test_source_tensor = string_to_tensor(preprocess(test_source, start_token, end_token, pad_token), en_l2i).transpose(0,1).requires_grad_(False)\n",
    "test_target_tensor = string_to_tensor(preprocess(test_target, start_token, end_token, pad_token), tr_l2i).transpose(0,1).requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers = 1, p = 0, bi_dir = False, rnn_class = nn.GRU):\n",
    "        \"\"\"\n",
    "        Init Parameters:\n",
    "        input_size : english_dict_count\n",
    "        embedding_size : size of each embedding vector\n",
    "        hidden_size : size of hidden state vector\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "        rnn_class: type of RNN to be used in the encoder\n",
    "\n",
    "        Input:\n",
    "        x : torch.Tensor of shape (seq_length, N)\n",
    "            where seq_length - len of longest string in the batch\n",
    "            N - batch size\n",
    "        \n",
    "        Outpus:\n",
    "        outputs: torch.Tensor of shape (seq_len, N, hidden_size * D), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size) if(rnn_class == \"LSTM\")\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn_class= rnn_class\n",
    "        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            outputs, (hidden, cell) = self.rnn(embedding)\n",
    "            # outputs shape: (seq_length, N, hidden_size)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedding)\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            return outputs, hidden, cell\n",
    "        else:\n",
    "            return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers = 1, p = 0, bi_dir = False, rnn_class = nn.GRU):\n",
    "        \"\"\"input size = output size = target language charecters\n",
    "        Init Parameters:\n",
    "        input_size: target_dict_count\n",
    "        embedding_size: size of each embedding vector\n",
    "        hidden_size: size of hidden state vector\n",
    "        output_size: number of output features in fully connected layer\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "        rnn_class: type of RNN to be used in the encoder\n",
    "\n",
    "        Input:\n",
    "        x: torch.Tensor of shape (N)\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "\n",
    "        Outputs:\n",
    "        predications: torch.Tensor of shape (N, target_dict_count), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size) if(rnn_class == \"LSTM\")\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn_class = rnn_class\n",
    "        self.rnn = rnn_class(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "        self.D = 1\n",
    "        if(bi_dir == True):\n",
    "            self.D = 2\n",
    "        self.fc = nn.Linear(hidden_size * self.D, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, cell = None):\n",
    "        #cell is set to none, for GRU and RNN\n",
    "\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        # print(x.shape, hidden.shape, cell.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "            # outputs shape: (1, N, hidden_size * D)\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedding, hidden)\n",
    "            \n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            return predictions, hidden, cell\n",
    "        else:\n",
    "            return predictions, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        encoder_layers = encoder.num_layers\n",
    "        decoder_layers = decoder.num_layers\n",
    "        D = decoder.D #we set bidiretion as common in both encoder and decoder, so no need to check for D value seperately\n",
    "        self.enc_to_dec = nn.Linear(encoder_layers*D, decoder_layers*D)\n",
    "        self.rnn_class = decoder.rnn_class #we use same rnn in both encoder and decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        \"\"\"source : (source_len, N) - not sure\n",
    "        teacher_forching_ratio : probability in which original values is favored over predicted values\n",
    "                                if 0 : predicted values is passed for all chars in target\n",
    "                                if 1 : true values is passed for all chars in target\n",
    "\n",
    "        \"\"\"\n",
    "        batch_size = source.shape[1] \n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = target_dict_count\n",
    "\n",
    "        # print(\"source shape \", source.shape)\n",
    "        # print(\"target shape \", target.shape)\n",
    "        # print(\"N : \", batch_size)\n",
    "        # print(\"tar len : \", target_len)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "        # print(\"outputs shape : \", outputs.shape)\n",
    "\n",
    "        \n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            _, hidden, cell = self.encoder(source)\n",
    "        else:\n",
    "            _, hidden = self.encoder(source)\n",
    "\n",
    "        N = hidden.shape[1]\n",
    "        hidden_size= hidden.shape[2]\n",
    "        # hidden, cell shape: (D*encoder_layers, N, hidden_size)\n",
    "\n",
    "        hidden = hidden.transpose(0, 2) # hidden shape: (hidden_size, N, D*encoder_layers)\n",
    "        hidden = hidden.reshape(-1, hidden.shape[2]) # hidden shape: (hidden_size * N, D*encoder_layers)\n",
    "        hidden = self.enc_to_dec(hidden) # hidden shape: (hidden_size * N, D*decoder_layers)\n",
    "        hidden = hidden.reshape(hidden_size, N, hidden.shape[1]) # hidden shape: (hidden_size, N, D*decoder_layers)\n",
    "        hidden = hidden.transpose(0,2) # hidden shape: (D*decoder_layers, N, hidden_size)\n",
    "\n",
    "        if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "            #at all the below steps, cell will have the shape of hidden\n",
    "            cell = cell.transpose(0,2)\n",
    "            cell = cell.reshape(-1, cell.shape[2])\n",
    "            cell = self.enc_to_dec(cell)\n",
    "            cell = cell.reshape(hidden_size, N, cell.shape[1])\n",
    "            cell = cell.transpose(0,2)\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "        outputs[:, :, tr_l2i[start_token]] = 1 #setting prob = 1 for starting token \n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            if(self.rnn_class.__name__ == \"LSTM\"):\n",
    "                output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = self.decoder(x, hidden)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        # print(\"OUTPUTS: \", outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def calc_evaluation_loss(self, soruce_strings, target_strings, batch_size = 32):\n",
    "        running_loss  = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(soruce_strings), batch_size):\n",
    "                inp_data = string_to_tensor(preprocess(soruce_strings[i:i+batch_size], start_token, end_token, pad_token), en_l2i).transpose(0,1)\n",
    "                target = string_to_tensor(preprocess(target_strings[i:i+batch_size], start_token, end_token, pad_token), tr_l2i).transpose(0,1)\n",
    "\n",
    "                output = self(inp_data, target)\n",
    "                output = output.reshape(-1, output.shape[2])\n",
    "                target = target.reshape(-1)\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "batch_size = 3\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = english_dict_count\n",
    "input_size_decoder = target_dict_count\n",
    "output_size = target_dict_count\n",
    "embedding_size = 16\n",
    "encoder_layers = 2\n",
    "decoder_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "hidden_size = 10\n",
    "bi_directional = False\n",
    "rnn = nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(english_dict_count, embedding_size, hidden_size, \n",
    "              num_layers=encoder_layers, \n",
    "              bi_dir=bi_directional,\n",
    "              p=enc_dropout,\n",
    "              rnn_class=rnn)\n",
    "dec = Decoder(target_dict_count, embedding_size, hidden_size, target_dict_count, \n",
    "              num_layers=decoder_layers, \n",
    "              bi_dir=bi_directional, \n",
    "              p = dec_dropout,\n",
    "              rnn_class=rnn)\n",
    "\n",
    "mod = Seq2Seq(enc, dec)\n",
    "\n",
    "optimizer = optim.Adam(mod.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_print(output):\n",
    "    \"\"\"output shape: target_seq_length * N\"\"\"\n",
    "    res = []\n",
    "    for j in range(output.shape[1]):\n",
    "        temp = \"\"\n",
    "        for i in range(output.shape[0]):\n",
    "            temp += tr_i2l[output[i,j].item()]\n",
    "        \n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1 / 100] \t Loss: 3.8891 \t Val Loss: 3.8232\n",
      "[Epoch   2 / 100] \t Loss: 3.8944 \t Val Loss: 3.8285\n",
      "[Epoch   3 / 100] \t Loss: 3.8710 \t Val Loss: 3.8186\n",
      "[Epoch   4 / 100] \t Loss: 3.9057 \t Val Loss: 3.8288\n",
      "[Epoch   5 / 100] \t Loss: 3.8991 \t Val Loss: 3.8136\n",
      "[Epoch   6 / 100] \t Loss: 3.8670 \t Val Loss: 3.8234\n",
      "[Epoch   7 / 100] \t Loss: 3.8864 \t Val Loss: 3.8198\n",
      "[Epoch   8 / 100] \t Loss: 3.8866 \t Val Loss: 3.8177\n",
      "[Epoch   9 / 100] \t Loss: 3.8555 \t Val Loss: 3.7997\n",
      "[Epoch  10 / 100] \t Loss: 3.8262 \t Val Loss: 3.8131\n",
      "[Epoch  11 / 100] \t Loss: 3.8477 \t Val Loss: 3.8145\n",
      "[Epoch  12 / 100] \t Loss: 3.8227 \t Val Loss: 3.8029\n",
      "[Epoch  13 / 100] \t Loss: 3.8299 \t Val Loss: 3.7893\n",
      "[Epoch  14 / 100] \t Loss: 3.8435 \t Val Loss: 3.8128\n",
      "[Epoch  15 / 100] \t Loss: 3.8195 \t Val Loss: 3.7849\n",
      "[Epoch  16 / 100] \t Loss: 3.7997 \t Val Loss: 3.7947\n",
      "[Epoch  17 / 100] \t Loss: 3.8073 \t Val Loss: 3.8124\n",
      "[Epoch  18 / 100] \t Loss: 3.7805 \t Val Loss: 3.7996\n",
      "[Epoch  19 / 100] \t Loss: 3.8180 \t Val Loss: 3.7947\n",
      "[Epoch  20 / 100] \t Loss: 3.7877 \t Val Loss: 3.7833\n",
      "[Epoch  21 / 100] \t Loss: 3.8025 \t Val Loss: 3.7882\n",
      "[Epoch  22 / 100] \t Loss: 3.7915 \t Val Loss: 3.7795\n",
      "[Epoch  23 / 100] \t Loss: 3.7551 \t Val Loss: 3.7789\n",
      "[Epoch  24 / 100] \t Loss: 3.7778 \t Val Loss: 3.7644\n",
      "[Epoch  25 / 100] \t Loss: 3.7566 \t Val Loss: 3.7544\n",
      "[Epoch  26 / 100] \t Loss: 3.7707 \t Val Loss: 3.7798\n",
      "[Epoch  27 / 100] \t Loss: 3.7753 \t Val Loss: 3.7663\n",
      "[Epoch  28 / 100] \t Loss: 3.7487 \t Val Loss: 3.7594\n",
      "[Epoch  29 / 100] \t Loss: 3.7456 \t Val Loss: 3.7546\n",
      "[Epoch  30 / 100] \t Loss: 3.7485 \t Val Loss: 3.7694\n",
      "[Epoch  31 / 100] \t Loss: 3.7340 \t Val Loss: 3.7550\n",
      "[Epoch  32 / 100] \t Loss: 3.7388 \t Val Loss: 3.7215\n",
      "[Epoch  33 / 100] \t Loss: 3.7244 \t Val Loss: 3.7547\n",
      "[Epoch  34 / 100] \t Loss: 3.7145 \t Val Loss: 3.7595\n",
      "[Epoch  35 / 100] \t Loss: 3.6841 \t Val Loss: 3.7602\n",
      "[Epoch  36 / 100] \t Loss: 3.6793 \t Val Loss: 3.7500\n",
      "[Epoch  37 / 100] \t Loss: 3.7000 \t Val Loss: 3.7374\n",
      "[Epoch  38 / 100] \t Loss: 3.6523 \t Val Loss: 3.7529\n",
      "[Epoch  39 / 100] \t Loss: 3.6653 \t Val Loss: 3.7352\n",
      "[Epoch  40 / 100] \t Loss: 3.6520 \t Val Loss: 3.7385\n",
      "[Epoch  41 / 100] \t Loss: 3.6310 \t Val Loss: 3.6903\n",
      "[Epoch  42 / 100] \t Loss: 3.6297 \t Val Loss: 3.7056\n",
      "[Epoch  43 / 100] \t Loss: 3.6389 \t Val Loss: 3.7480\n",
      "[Epoch  44 / 100] \t Loss: 3.6546 \t Val Loss: 3.6737\n",
      "[Epoch  45 / 100] \t Loss: 3.6275 \t Val Loss: 3.7237\n",
      "[Epoch  46 / 100] \t Loss: 3.6457 \t Val Loss: 3.7128\n",
      "[Epoch  47 / 100] \t Loss: 3.6059 \t Val Loss: 3.6977\n",
      "[Epoch  48 / 100] \t Loss: 3.5857 \t Val Loss: 3.7164\n",
      "[Epoch  49 / 100] \t Loss: 3.5565 \t Val Loss: 3.7471\n",
      "[Epoch  50 / 100] \t Loss: 3.5962 \t Val Loss: 3.7142\n",
      "[Epoch  51 / 100] \t Loss: 3.5782 \t Val Loss: 3.7125\n",
      "[Epoch  52 / 100] \t Loss: 3.5514 \t Val Loss: 3.7218\n",
      "[Epoch  53 / 100] \t Loss: 3.5273 \t Val Loss: 3.7421\n",
      "[Epoch  54 / 100] \t Loss: 3.5156 \t Val Loss: 3.6585\n",
      "[Epoch  55 / 100] \t Loss: 3.5087 \t Val Loss: 3.6775\n",
      "[Epoch  56 / 100] \t Loss: 3.5185 \t Val Loss: 3.6593\n",
      "[Epoch  57 / 100] \t Loss: 3.5291 \t Val Loss: 3.6851\n",
      "[Epoch  58 / 100] \t Loss: 3.4712 \t Val Loss: 3.7025\n",
      "[Epoch  59 / 100] \t Loss: 3.4966 \t Val Loss: 3.7131\n",
      "[Epoch  60 / 100] \t Loss: 3.5056 \t Val Loss: 3.6873\n",
      "[Epoch  61 / 100] \t Loss: 3.4371 \t Val Loss: 3.6654\n",
      "[Epoch  62 / 100] \t Loss: 3.4153 \t Val Loss: 3.6738\n",
      "[Epoch  63 / 100] \t Loss: 3.4339 \t Val Loss: 3.6730\n",
      "[Epoch  64 / 100] \t Loss: 3.4022 \t Val Loss: 3.6947\n",
      "[Epoch  65 / 100] \t Loss: 3.4098 \t Val Loss: 3.6806\n",
      "[Epoch  66 / 100] \t Loss: 3.4403 \t Val Loss: 3.6621\n",
      "[Epoch  67 / 100] \t Loss: 3.3718 \t Val Loss: 3.6604\n",
      "[Epoch  68 / 100] \t Loss: 3.4112 \t Val Loss: 3.6464\n",
      "[Epoch  69 / 100] \t Loss: 3.3818 \t Val Loss: 3.6914\n",
      "[Epoch  70 / 100] \t Loss: 3.3593 \t Val Loss: 3.7160\n",
      "[Epoch  71 / 100] \t Loss: 3.3608 \t Val Loss: 3.6587\n",
      "[Epoch  72 / 100] \t Loss: 3.3876 \t Val Loss: 3.6556\n",
      "[Epoch  73 / 100] \t Loss: 3.3414 \t Val Loss: 3.6513\n",
      "[Epoch  74 / 100] \t Loss: 3.2394 \t Val Loss: 3.6514\n",
      "[Epoch  75 / 100] \t Loss: 3.2818 \t Val Loss: 3.6589\n",
      "[Epoch  76 / 100] \t Loss: 3.2730 \t Val Loss: 3.6887\n",
      "[Epoch  77 / 100] \t Loss: 3.2641 \t Val Loss: 3.6293\n",
      "[Epoch  78 / 100] \t Loss: 3.2997 \t Val Loss: 3.6548\n",
      "[Epoch  79 / 100] \t Loss: 3.2291 \t Val Loss: 3.6672\n",
      "[Epoch  80 / 100] \t Loss: 3.1860 \t Val Loss: 3.6190\n",
      "[Epoch  81 / 100] \t Loss: 3.2371 \t Val Loss: 3.6311\n",
      "[Epoch  82 / 100] \t Loss: 3.2037 \t Val Loss: 3.6540\n",
      "[Epoch  83 / 100] \t Loss: 3.1144 \t Val Loss: 3.6206\n",
      "[Epoch  84 / 100] \t Loss: 3.1460 \t Val Loss: 3.6304\n",
      "[Epoch  85 / 100] \t Loss: 3.1730 \t Val Loss: 3.5904\n",
      "[Epoch  86 / 100] \t Loss: 3.1016 \t Val Loss: 3.6041\n",
      "[Epoch  87 / 100] \t Loss: 3.1112 \t Val Loss: 3.6237\n",
      "[Epoch  88 / 100] \t Loss: 3.1250 \t Val Loss: 3.6329\n",
      "[Epoch  89 / 100] \t Loss: 3.1013 \t Val Loss: 3.5959\n",
      "[Epoch  90 / 100] \t Loss: 3.0994 \t Val Loss: 3.6074\n",
      "[Epoch  91 / 100] \t Loss: 3.0917 \t Val Loss: 3.5817\n",
      "[Epoch  92 / 100] \t Loss: 3.1293 \t Val Loss: 3.5696\n",
      "[Epoch  93 / 100] \t Loss: 3.0839 \t Val Loss: 3.6373\n",
      "[Epoch  94 / 100] \t Loss: 3.0041 \t Val Loss: 3.6116\n",
      "[Epoch  95 / 100] \t Loss: 3.0398 \t Val Loss: 3.5761\n",
      "[Epoch  96 / 100] \t Loss: 2.9906 \t Val Loss: 3.5760\n",
      "[Epoch  97 / 100] \t Loss: 3.0119 \t Val Loss: 3.5939\n",
      "[Epoch  98 / 100] \t Loss: 3.0167 \t Val Loss: 3.6034\n",
      "[Epoch  99 / 100] \t Loss: 3.0487 \t Val Loss: 3.4796\n",
      "[Epoch 100 / 100] \t Loss: 3.0093 \t Val Loss: 3.6142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25fbd371750>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_list = []\n",
    "init_teacher_forcing_ratio = 0.8\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    no_of_batch = 0\n",
    "    for i in range(0, len(train_source[:3]), batch_size):\n",
    "        src_strings = train_source[i: i+batch_size]\n",
    "        tar_strings = train_target[i: i+batch_size]\n",
    "\n",
    "        src_strings = preprocess(src_strings, start_token, end_token, pad_token)\n",
    "        tar_strings = preprocess(tar_strings, start_token, end_token, pad_token)\n",
    "\n",
    "        #transposing to make the shape as expected\n",
    "        inp_data = string_to_tensor(src_strings, en_l2i).transpose(0,1)\n",
    "        target = string_to_tensor(tar_strings, tr_l2i).transpose(0,1)\n",
    "\n",
    "        #here teacher forcing ratio will reduces linearly from init_teacher_forcing_ratio to 0 in half the number of epochs\n",
    "        teacher_forcing_ratio = max(0, init_teacher_forcing_ratio * (1 - (epoch*2/num_epochs)))\n",
    "        output = mod(inp_data, target, teacher_forcing_ratio)\n",
    "\n",
    "        # print(\"train: output : \", output.shape)\n",
    "        # result = temp_print(output.argmax(2))\n",
    "        # print(\"result: \", result)\n",
    "        # print(\"target: \", tar_strings)\n",
    "        \n",
    "        # print(\"output: \",result)\n",
    "        # print(\"target:\", tar_strings)\n",
    "\n",
    "        # print(\"op before reshopsed \", output.shape)\n",
    "        # print(\"tar before reshape: \", target.shape)\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "\n",
    "        # print(\"op: \", output.shape)\n",
    "        # print(\"tar: \", target.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mod.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        no_of_batch += 1        \n",
    "\n",
    "    # val_output = mod(val_source_tensor, val_target_tensor)\n",
    "    # val_output = val_output.reshape(-1, val_output.shape[2])\n",
    "    # val_target_tensor = val_target_tensor.reshape(-1)\n",
    "    # # print(f\"val output : {val_output.shape} \\t val_target: {val_target_tensor.shape}\")\n",
    "    # val_loss = criterion(val_output, val_target_tensor)\n",
    "\n",
    "    val_loss= mod.calc_evaluation_loss(val_source[:2], val_target[:2])\n",
    "    # val_loss = 0\n",
    "    \n",
    "    print(f\"[Epoch {epoch+1:3d} / {num_epochs}] \\t Loss: {(running_loss/no_of_batch):.4f} \\t Val Loss: {val_loss:2.4f}\")\n",
    "    loss_list.append(running_loss/no_of_batch)\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
