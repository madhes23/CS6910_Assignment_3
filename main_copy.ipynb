{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import preprocess, string_to_tensor\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'tam'\n",
    "start_token = '<'\n",
    "end_token = '>'\n",
    "pad_token = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'aksharantar_sampled/' + language\n",
    "\n",
    "train_df = pd.read_csv(path+'/'+language+'_train.csv', header=None)\n",
    "test_df = pd.read_csv(path+'/'+language+'_test.csv', header=None)\n",
    "val_df = pd.read_csv(path+'/'+language+'_valid.csv', header=None)\n",
    "\n",
    "train_source, train_target = train_df[0].tolist(), train_df[1].tolist()\n",
    "test_source, test_target = test_df[0].tolist(), test_df[1].tolist()\n",
    "val_source, val_target = val_df[0].tolist(), val_df[1].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thottacharya  -->  தொட்டாச்சார்ய\n",
      "menmaithaan  -->  மென்மைதான்\n",
      "avarantri  -->  அவரன்றி\n",
      "mudiyarathu  -->  முடியறது\n",
      "aadaiyanigalaal  -->  ஆடையணிகளால்\n"
     ]
    }
   ],
   "source": [
    "num_sample = 5\n",
    "for i in range(num_sample):\n",
    "    print(f'{train_source[i]}  -->  {train_target[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Charecters :  49\n",
      "Target Charecters: \n",
      "0  \t\n",
      "1 ழ\t2 ச\t3 ு\t4 ஷ\t5 ஓ\t\n",
      "6 ெ\t7 ள\t8 ூ\t9 உ\t10 ர\t\n",
      "11 ஞ\t12 ஈ\t13 >\t14 <\t15 ய\t\n",
      "16 இ\t17 ா\t18 ந\t19 ஐ\t20 ொ\t\n",
      "21 ஃ\t22 ோ\t23 எ\t24 ங\t25 ஏ\t\n",
      "26 ஸ\t27 ஆ\t28 ல\t29 ண\t30 வ\t\n",
      "31 ன\t32 ை\t33 க\t34 ஒ\t35 ஜ\t\n",
      "36 ௌ\t37 ஊ\t38 த\t39 ற\t40 ்\t\n",
      "41 ி\t42 ீ\t43 ஹ\t44 ப\t45 ம\t\n",
      "46 ட\t47 அ\t48 ே\t"
     ]
    }
   ],
   "source": [
    "english_chars = list(set(''.join(train_source) + start_token + end_token + pad_token))\n",
    "target_chars = list(set(''.join(train_target) + start_token + end_token + pad_token))\n",
    "\n",
    "english_dict_count = len(english_chars)\n",
    "target_dict_count = len(target_chars)\n",
    "\n",
    "print(\"Number of Charecters : \", target_dict_count)\n",
    "\n",
    "print(\"Target Charecters: \")\n",
    "for i, c in enumerate(target_chars):\n",
    "    print(i, c, end='\\t')\n",
    "    if i % 5 == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_i2l, en_l2i = {}, {}\n",
    "tr_i2l, tr_l2i = {}, {}\n",
    "\n",
    "for i, x in enumerate(english_chars):\n",
    "    en_l2i[x] = i\n",
    "    en_i2l[i] = x\n",
    "\n",
    "for i, x in enumerate(target_chars):\n",
    "    tr_l2i[x] = i\n",
    "    tr_i2l[i] = x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_source_tensor = string_to_tensor(preprocess(val_source, start_token, end_token, pad_token), en_l2i).transpose(0,1).requires_grad_(False)\n",
    "val_target_tensor = string_to_tensor(preprocess(val_target, start_token, end_token, pad_token), tr_l2i).transpose(0,1).requires_grad_(False)\n",
    "\n",
    "test_source_tensor = string_to_tensor(preprocess(test_source, start_token, end_token, pad_token), en_l2i).transpose(0,1).requires_grad_(False)\n",
    "test_target_tensor = string_to_tensor(preprocess(test_target, start_token, end_token, pad_token), tr_l2i).transpose(0,1).requires_grad_(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers = 1, p = 0, bi_dir = False):\n",
    "        \"\"\"\n",
    "        Init Parameters:\n",
    "        input_size : english_dict_count\n",
    "        embedding_size : size of each embedding vector\n",
    "        hidden_size : size of hidden state vector\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "\n",
    "        Input:\n",
    "        x : torch.Tensor of shape (seq_length, N)\n",
    "            where seq_length - len of longest string in the batch\n",
    "            N - batch size\n",
    "        \n",
    "        Outpus:\n",
    "        outputs: torch.Tensor of shape (seq_len, N, hidden_size * D), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, N) where N is batch size\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (seq_length, N, embedding_size)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        # outputs shape: (seq_length, N, hidden_size)\n",
    "        \n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers = 1, p = 0, bi_dir = False):\n",
    "        \"\"\"input size = output size = target language charecters\n",
    "        Init Parameters:\n",
    "        input_size: target_dict_count\n",
    "        embedding_size: size of each embedding vector\n",
    "        hidden_size: size of hidden state vector\n",
    "        output_size: number of output features in fully connected layer\n",
    "        num_layers : number of recurrent layers of RNN\n",
    "        p : dropout probability\n",
    "\n",
    "        Input:\n",
    "        x: torch.Tensor of shape (N)\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "\n",
    "        Outputs:\n",
    "        predications: torch.Tensor of shape (N, target_dict_count), where D = 2 if bi_dir = True else 1\n",
    "        hidden: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        cell: torch.Tensor of shape (num_layers * D, N, hidden_size)\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = bi_dir)\n",
    "        self.D = 1\n",
    "        if(bi_dir == True):\n",
    "            self.D = 2\n",
    "        self.fc = nn.Linear(hidden_size * self.D, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: (N) where N is for batch size, we want it to be (1, N), seq_length\n",
    "        # is 1 here because we are sending in a single word and not a sentence\n",
    "        # print(x.shape, hidden.shape, cell.shape)\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (1, N, embedding_size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
    "        # outputs shape: (1, N, hidden_size * D)\n",
    "\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # predictions shape: (1, N, length_target_vocabulary) to send it to\n",
    "        # loss function we want it to be (N, length_target_vocabulary) so we're\n",
    "        # just gonna remove the first dim\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        encoder_layers = encoder.num_layers\n",
    "        decoder_layers = decoder.num_layers\n",
    "        D = decoder.D #we set bidiretion as common in both encoder and decoder, so no need to check for D value seperately\n",
    "        self.enc_to_dec = nn.Linear(encoder_layers*D, decoder_layers*D)\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        \"\"\"source : (source_len, N) - not sure\n",
    "        \"\"\"\n",
    "        batch_size = source.shape[1] \n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = target_dict_count\n",
    "\n",
    "        # print(\"source shape \", source.shape)\n",
    "        # print(\"target shape \", target.shape)\n",
    "        # print(\"N : \", batch_size)\n",
    "        # print(\"tar len : \", target_len)\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "        # print(\"outputs shape : \", outputs.shape)\n",
    "\n",
    "        _, hidden, cell = self.encoder(source)\n",
    "        N = hidden.shape[1]\n",
    "        hidden_size= hidden.shape[2]\n",
    "        # hidden, cell shape: (D*encoder_layers, N, hidden_size)\n",
    "\n",
    "        hidden = hidden.transpose(0, 2)\n",
    "        cell = cell.transpose(0,2)\n",
    "        # hidden, cell shape: (hidden_size, N, D*encoder_layers)\n",
    "\n",
    "        hidden = hidden.reshape(-1, hidden.shape[2])\n",
    "        cell = cell.reshape(-1, cell.shape[2])\n",
    "        # hidden, cell shape: (hidden_size * N, D*encoder_layers)\n",
    "\n",
    "        hidden = self.enc_to_dec(hidden)\n",
    "        cell = self.enc_to_dec(cell)\n",
    "        # hidden, cell shape: (hidden_size * N, D*decoder_layers)\n",
    "\n",
    "\n",
    "        hidden = hidden.reshape(hidden_size, N, hidden.shape[1])\n",
    "        cell = cell.reshape(hidden_size, N, cell.shape[1])\n",
    "        # hidden, cell shape: (hidden_size, N, D*decoder_layers)\n",
    "\n",
    "\n",
    "        hidden = hidden.transpose(0,2)\n",
    "        cell = cell.transpose(0,2)\n",
    "        # hidden, cell shape: (D*decoder_layers, N, hidden_size)\n",
    "\n",
    "\n",
    "        # Grab the first input to the Decoder which will be <SOS> token\n",
    "        x = target[0]\n",
    "        outputs[:, :, tr_l2i[start_token]] = 1 #setting prob = 1 for starting token \n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            # Use previous hidden, cell as context from encoder at start\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "\n",
    "            # Store next output prediction\n",
    "            outputs[t] = output\n",
    "\n",
    "            # Get the best word the Decoder predicted (index in the vocabulary)\n",
    "            best_guess = output.argmax(1)\n",
    "\n",
    "            # With probability of teacher_force_ratio we take the actual next word\n",
    "            # otherwise we take the word that the Decoder predicted it to be.\n",
    "            # Teacher Forcing is used so that the model gets used to seeing\n",
    "            # similar inputs at training and testing time, if teacher forcing is 1\n",
    "            # then inputs at test time might be completely different than what the\n",
    "            # network is used to. This was a long comment.\n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "        # print(\"OUTPUTS: \", outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def calc_evaluation_loss(self, soruce_strings, target_strings, batch_size = 32):\n",
    "        running_loss  = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(soruce_strings), batch_size):\n",
    "                inp_data = string_to_tensor(preprocess(soruce_strings[i:i+batch_size], start_token, end_token, pad_token), en_l2i).transpose(0,1)\n",
    "                target = string_to_tensor(preprocess(target_strings[i:i+batch_size], start_token, end_token, pad_token), tr_l2i).transpose(0,1)\n",
    "\n",
    "                output = self(inp_data, target)\n",
    "                output = output.reshape(-1, output.shape[2])\n",
    "                target = target.reshape(-1)\n",
    "\n",
    "                loss = criterion(output, target)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "        return running_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 500\n",
    "learning_rate = 0.001\n",
    "batch_size = 2\n",
    "\n",
    "# Model hyperparameters\n",
    "load_model = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size_encoder = english_dict_count\n",
    "input_size_decoder = target_dict_count\n",
    "output_size = target_dict_count\n",
    "encoder_embedding_size = 10\n",
    "decoder_embedding_size = 10\n",
    "encoder_layers = 1\n",
    "decoder_layers = 1\n",
    "enc_dropout = 0\n",
    "dec_dropout = 0\n",
    "embedding_size= 16\n",
    "hidden_size = 10\n",
    "bi_directional = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(english_dict_count, embedding_size, hidden_size, num_layers=encoder_layers, bi_dir=bi_directional)\n",
    "dec = Decoder(target_dict_count, embedding_size, hidden_size, target_dict_count, num_layers=decoder_layers, bi_dir=bi_directional)\n",
    "\n",
    "mod = Seq2Seq(enc, dec)\n",
    "\n",
    "optimizer = optim.Adam(mod.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_print(output):\n",
    "    \"\"\"output shape: target_seq_length * N\"\"\"\n",
    "    res = []\n",
    "    for j in range(output.shape[1]):\n",
    "        temp = \"\"\n",
    "        for i in range(output.shape[0]):\n",
    "            temp += tr_i2l[output[i,j].item()]\n",
    "        \n",
    "        res.append(temp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்்்>>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   1 / 500] \t Loss: 1.7393 \t Val Loss: 3.9293\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   2 / 500] \t Loss: 1.6131 \t Val Loss: 3.8485\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   3 / 500] \t Loss: 1.6304 \t Val Loss: 3.6637\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்ா>ட', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   4 / 500] \t Loss: 1.6836 \t Val Loss: 3.8964\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்ா>', '<மென்மனதான்்்் ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   5 / 500] \t Loss: 1.6588 \t Val Loss: 3.7434\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   6 / 500] \t Loss: 1.6292 \t Val Loss: 3.8255\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   7 / 500] \t Loss: 1.6247 \t Val Loss: 3.8043\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்் ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   8 / 500] \t Loss: 1.6506 \t Val Loss: 3.8808\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch   9 / 500] \t Loss: 1.6615 \t Val Loss: 3.6842\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்்ா']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  10 / 500] \t Loss: 1.6835 \t Val Loss: 3.9093\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  11 / 500] \t Loss: 1.6002 \t Val Loss: 3.7664\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  12 / 500] \t Loss: 1.6328 \t Val Loss: 3.8316\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  13 / 500] \t Loss: 1.6138 \t Val Loss: 3.6824\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  14 / 500] \t Loss: 1.6021 \t Val Loss: 3.7971\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மன்்்்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  15 / 500] \t Loss: 1.7004 \t Val Loss: 3.8041\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்்்்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  16 / 500] \t Loss: 1.7005 \t Val Loss: 3.7380\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  17 / 500] \t Loss: 1.6035 \t Val Loss: 3.7921\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  18 / 500] \t Loss: 1.5936 \t Val Loss: 3.9716\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  19 / 500] \t Loss: 1.5986 \t Val Loss: 3.8953\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்் >', '<மென்மன்்ன்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  20 / 500] \t Loss: 1.7085 \t Val Loss: 3.7679\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்  ', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  21 / 500] \t Loss: 1.6636 \t Val Loss: 3.6809\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  22 / 500] \t Loss: 1.6287 \t Val Loss: 3.7890\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  23 / 500] \t Loss: 1.5726 \t Val Loss: 3.7579\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்்>>', '<மென்மன்்்>>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  24 / 500] \t Loss: 1.7211 \t Val Loss: 3.7322\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  25 / 500] \t Loss: 1.5725 \t Val Loss: 3.8501\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  26 / 500] \t Loss: 1.5681 \t Val Loss: 3.8678\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்்்்', '<மென்மன்்ன்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  27 / 500] \t Loss: 1.6495 \t Val Loss: 3.7288\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்>்']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  28 / 500] \t Loss: 1.6295 \t Val Loss: 3.6326\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  29 / 500] \t Loss: 1.6032 \t Val Loss: 3.6764\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  30 / 500] \t Loss: 1.5889 \t Val Loss: 3.8107\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  31 / 500] \t Loss: 1.5804 \t Val Loss: 3.7647\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>் >', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  32 / 500] \t Loss: 1.6258 \t Val Loss: 3.7415\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  33 / 500] \t Loss: 1.5671 \t Val Loss: 3.7907\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்்>', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  34 / 500] \t Loss: 1.6219 \t Val Loss: 3.7757\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  35 / 500] \t Loss: 1.5929 \t Val Loss: 3.7572\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மன்்்்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  36 / 500] \t Loss: 1.6551 \t Val Loss: 3.6812\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  37 / 500] \t Loss: 1.5418 \t Val Loss: 3.9043\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்ான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  38 / 500] \t Loss: 1.5760 \t Val Loss: 3.9117\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>> ', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  39 / 500] \t Loss: 1.5960 \t Val Loss: 3.8507\n",
      "\n",
      "result:  ['<தொட்ட்்்>    ட', '<மென்மன்்ன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  40 / 500] \t Loss: 1.7281 \t Val Loss: 3.8637\n",
      "\n",
      "result:  ['<தொட்ட்்்>்்்்>', '<மென்மன்்்்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  41 / 500] \t Loss: 1.6465 \t Val Loss: 3.8732\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  42 / 500] \t Loss: 1.5318 \t Val Loss: 3.7397\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>  ', '<மென்மன்்ன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  43 / 500] \t Loss: 1.7501 \t Val Loss: 3.8290\n",
      "\n",
      "result:  ['<தொட்ட்்்்> ் >', '<மென்மன்்்>    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  44 / 500] \t Loss: 1.7348 \t Val Loss: 3.7150\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  45 / 500] \t Loss: 1.5753 \t Val Loss: 3.8496\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மன்்்்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  46 / 500] \t Loss: 1.6806 \t Val Loss: 3.5794\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்்்்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  47 / 500] \t Loss: 1.6371 \t Val Loss: 3.9059\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மன்ான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  48 / 500] \t Loss: 1.6188 \t Val Loss: 3.8149\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்ான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  49 / 500] \t Loss: 1.5568 \t Val Loss: 3.7817\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  50 / 500] \t Loss: 1.5108 \t Val Loss: 3.9190\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  51 / 500] \t Loss: 1.5038 \t Val Loss: 3.9764\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  52 / 500] \t Loss: 1.5124 \t Val Loss: 3.8356\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  53 / 500] \t Loss: 1.5245 \t Val Loss: 4.0248\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  54 / 500] \t Loss: 1.5134 \t Val Loss: 3.8995\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மன்ான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  55 / 500] \t Loss: 1.6071 \t Val Loss: 3.8920\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  56 / 500] \t Loss: 1.5677 \t Val Loss: 3.7159\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மன்ான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  57 / 500] \t Loss: 1.5530 \t Val Loss: 3.8461\n",
      "\n",
      "result:  ['<தொட்ட்்்்> ் >', '<மென்மன்்ன்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  58 / 500] \t Loss: 1.6225 \t Val Loss: 3.6538\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  59 / 500] \t Loss: 1.4710 \t Val Loss: 3.8974\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்்்்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  60 / 500] \t Loss: 1.6122 \t Val Loss: 3.8162\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்்ன்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  61 / 500] \t Loss: 1.5603 \t Val Loss: 3.7935\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  62 / 500] \t Loss: 1.4635 \t Val Loss: 3.7225\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மன்்்்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  63 / 500] \t Loss: 1.6097 \t Val Loss: 3.6987\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்> ', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  64 / 500] \t Loss: 1.5428 \t Val Loss: 3.9428\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்ான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  65 / 500] \t Loss: 1.5288 \t Val Loss: 3.8486\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  66 / 500] \t Loss: 1.5404 \t Val Loss: 3.8468\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  67 / 500] \t Loss: 1.4940 \t Val Loss: 3.7981\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  68 / 500] \t Loss: 1.4477 \t Val Loss: 3.6361\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  69 / 500] \t Loss: 1.4653 \t Val Loss: 3.7981\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  70 / 500] \t Loss: 1.4627 \t Val Loss: 3.7961\n",
      "\n",
      "result:  ['<தொட்ட்்்>     ', '<மென்மன்மன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  71 / 500] \t Loss: 1.7312 \t Val Loss: 3.7500\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  72 / 500] \t Loss: 1.5169 \t Val Loss: 3.7451\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  73 / 500] \t Loss: 1.4858 \t Val Loss: 4.0399\n",
      "\n",
      "result:  ['<தொட்ட்்்>்்்> ', '<மென்மன்மன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  74 / 500] \t Loss: 1.6308 \t Val Loss: 3.7876\n",
      "\n",
      "result:  ['<தொட்ட்்்்>   ட', '<மென்மன்ான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  75 / 500] \t Loss: 1.6703 \t Val Loss: 3.8132\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  76 / 500] \t Loss: 1.4455 \t Val Loss: 3.4919\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்> ட', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  77 / 500] \t Loss: 1.5447 \t Val Loss: 3.7313\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மன்ான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  78 / 500] \t Loss: 1.5094 \t Val Loss: 3.6926\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>   ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  79 / 500] \t Loss: 1.6086 \t Val Loss: 3.6543\n",
      "\n",
      "result:  ['<தொட்ட்்்>்>  >', '<மென்மன்மன்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  80 / 500] \t Loss: 1.5644 \t Val Loss: 3.7912\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  81 / 500] \t Loss: 1.4400 \t Val Loss: 3.9487\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>>>', '<மென்மன்ான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  82 / 500] \t Loss: 1.5299 \t Val Loss: 3.8441\n",
      "\n",
      "result:  ['<தொட்ட்்்்>    ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  83 / 500] \t Loss: 1.6256 \t Val Loss: 3.8394\n",
      "\n",
      "result:  ['<தொட்ட்்்>்்்்>', '<மென்மன்மன்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  84 / 500] \t Loss: 1.5086 \t Val Loss: 3.9004\n",
      "\n",
      "result:  ['<தொட்ட்்்>    >', '<மென்மன்மன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  85 / 500] \t Loss: 1.6048 \t Val Loss: 3.7274\n",
      "\n",
      "result:  ['<தொட்ட்்்>்்்> ', '<மென்மன்மன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  86 / 500] \t Loss: 1.5966 \t Val Loss: 3.8800\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  87 / 500] \t Loss: 1.4484 \t Val Loss: 3.6465\n",
      "\n",
      "result:  ['<தொட்ட்்்>்>்> ', '<மென்மன்்>்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  88 / 500] \t Loss: 1.6390 \t Val Loss: 3.8913\n",
      "\n",
      "result:  ['<தொட்ட்்்>     ', '<மென்மன்்ன்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  89 / 500] \t Loss: 1.7249 \t Val Loss: 3.7535\n",
      "\n",
      "result:  ['<தொட்ட்்்> ச்்>', '<மென்மன்்>     ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  90 / 500] \t Loss: 1.5934 \t Val Loss: 3.6713\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்> ட', '<மென்மன்ான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  91 / 500] \t Loss: 1.5891 \t Val Loss: 3.7751\n",
      "\n",
      "result:  ['<தொட்ட்்்்>   >', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  92 / 500] \t Loss: 1.5555 \t Val Loss: 3.7301\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  93 / 500] \t Loss: 1.4428 \t Val Loss: 3.9031\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  94 / 500] \t Loss: 1.5404 \t Val Loss: 3.7385\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்்்>', '<மென்மன்்ன்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  95 / 500] \t Loss: 1.4887 \t Val Loss: 3.9568\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  96 / 500] \t Loss: 1.4151 \t Val Loss: 3.6542\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மன்்ன்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  97 / 500] \t Loss: 1.4770 \t Val Loss: 3.6323\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மன்ான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  98 / 500] \t Loss: 1.5272 \t Val Loss: 3.7910\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மன்ான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch  99 / 500] \t Loss: 1.4484 \t Val Loss: 3.7626\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மனதான்்்  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 100 / 500] \t Loss: 1.4821 \t Val Loss: 3.8739\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்்> ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 101 / 500] \t Loss: 1.4859 \t Val Loss: 3.6444\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மன்மத்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 102 / 500] \t Loss: 1.4862 \t Val Loss: 3.6912\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 103 / 500] \t Loss: 1.4136 \t Val Loss: 3.5418\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>> ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 104 / 500] \t Loss: 1.4715 \t Val Loss: 3.5808\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>  ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 105 / 500] \t Loss: 1.5403 \t Val Loss: 3.8513\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்>> ', '<மென்மன்மதா    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 106 / 500] \t Loss: 1.5661 \t Val Loss: 3.7374\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்>>', '<மென்மன்ான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 107 / 500] \t Loss: 1.4319 \t Val Loss: 3.6314\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 108 / 500] \t Loss: 1.4105 \t Val Loss: 3.8649\n",
      "\n",
      "result:  ['<தொட்ட்்்்்> >>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 109 / 500] \t Loss: 1.4564 \t Val Loss: 3.9302\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்்்>', '<மென்மன்்> >   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 110 / 500] \t Loss: 1.5760 \t Val Loss: 3.5820\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>   ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 111 / 500] \t Loss: 1.5567 \t Val Loss: 3.7085\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 112 / 500] \t Loss: 1.3792 \t Val Loss: 3.6358\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 113 / 500] \t Loss: 1.3779 \t Val Loss: 3.8596\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 114 / 500] \t Loss: 1.3562 \t Val Loss: 3.6725\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 115 / 500] \t Loss: 1.4155 \t Val Loss: 3.8746\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 116 / 500] \t Loss: 1.4532 \t Val Loss: 3.9575\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 117 / 500] \t Loss: 1.4278 \t Val Loss: 3.8900\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>   ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 118 / 500] \t Loss: 1.5666 \t Val Loss: 3.4328\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 119 / 500] \t Loss: 1.4453 \t Val Loss: 3.6150\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 120 / 500] \t Loss: 1.3576 \t Val Loss: 3.6933\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 121 / 500] \t Loss: 1.3548 \t Val Loss: 3.5849\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மனத  ்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 122 / 500] \t Loss: 1.5412 \t Val Loss: 3.5800\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 123 / 500] \t Loss: 1.3379 \t Val Loss: 3.7395\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>> ', '<மென்மனத  ்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 124 / 500] \t Loss: 1.5634 \t Val Loss: 3.5941\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 125 / 500] \t Loss: 1.3673 \t Val Loss: 3.8864\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்>>', '<மென்மனத       ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 126 / 500] \t Loss: 1.5925 \t Val Loss: 3.5012\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 127 / 500] \t Loss: 1.3267 \t Val Loss: 3.7920\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>   ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 128 / 500] \t Loss: 1.5142 \t Val Loss: 3.6944\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்> ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 129 / 500] \t Loss: 1.3963 \t Val Loss: 4.0027\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>  >', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 130 / 500] \t Loss: 1.4028 \t Val Loss: 3.9021\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>  ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 131 / 500] \t Loss: 1.4808 \t Val Loss: 3.8028\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 132 / 500] \t Loss: 1.3213 \t Val Loss: 3.6356\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 133 / 500] \t Loss: 1.3700 \t Val Loss: 3.7804\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 134 / 500] \t Loss: 1.3575 \t Val Loss: 3.8430\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 135 / 500] \t Loss: 1.3642 \t Val Loss: 3.6982\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 136 / 500] \t Loss: 1.3747 \t Val Loss: 3.4643\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 137 / 500] \t Loss: 1.3082 \t Val Loss: 4.0219\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்>>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 138 / 500] \t Loss: 1.3734 \t Val Loss: 3.9277\n",
      "\n",
      "result:  ['<தொட்ட்்்்>்>> ', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 139 / 500] \t Loss: 1.3844 \t Val Loss: 3.6940\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>>', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 140 / 500] \t Loss: 1.3414 \t Val Loss: 3.5783\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 141 / 500] \t Loss: 1.3282 \t Val Loss: 3.5925\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 142 / 500] \t Loss: 1.2746 \t Val Loss: 3.6625\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>்', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 143 / 500] \t Loss: 1.3799 \t Val Loss: 3.6751\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்>்', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 144 / 500] \t Loss: 1.3773 \t Val Loss: 4.1014\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 145 / 500] \t Loss: 1.2757 \t Val Loss: 4.1221\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்்', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 146 / 500] \t Loss: 1.2894 \t Val Loss: 3.8649\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 147 / 500] \t Loss: 1.2704 \t Val Loss: 3.9519\n",
      "\n",
      "result:  ['<தொட்ட்்்>    ட', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 148 / 500] \t Loss: 1.4801 \t Val Loss: 3.8944\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 149 / 500] \t Loss: 1.2832 \t Val Loss: 3.5856\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>  >', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 150 / 500] \t Loss: 1.3568 \t Val Loss: 3.8706\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்> ', '<மென்மனதான்    ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 151 / 500] \t Loss: 1.3744 \t Val Loss: 3.9897\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 152 / 500] \t Loss: 1.2623 \t Val Loss: 3.9221\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 153 / 500] \t Loss: 1.2861 \t Val Loss: 3.7939\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்>்>>', '<மென்மனதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 154 / 500] \t Loss: 1.2649 \t Val Loss: 3.6425\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்>>', '<மென்மனதான்்>  ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 155 / 500] \t Loss: 1.3116 \t Val Loss: 3.8781\n",
      "\n",
      "result:  ['<தொட்ட்்்்்ச்்>', '<மென்மைதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 156 / 500] \t Loss: 1.2533 \t Val Loss: 3.6121\n",
      "\n",
      "result:  ['<தொட்ட்்்்்ச்்>', '<மென்மைதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 157 / 500] \t Loss: 1.2505 \t Val Loss: 3.7823\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மைதான்்   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 158 / 500] \t Loss: 1.2324 \t Val Loss: 3.7213\n",
      "\n",
      "result:  ['<தொட்ட்்்்்்்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 159 / 500] \t Loss: 1.2485 \t Val Loss: 3.9410\n",
      "\n",
      "result:  ['<தொட்ட்்்> ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 160 / 500] \t Loss: 1.2573 \t Val Loss: 3.5972\n",
      "\n",
      "result:  ['<தொட்ட்்்>்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 161 / 500] \t Loss: 1.2638 \t Val Loss: 3.9496\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 162 / 500] \t Loss: 1.2250 \t Val Loss: 3.6876\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்>> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 163 / 500] \t Loss: 1.2836 \t Val Loss: 3.6321\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 164 / 500] \t Loss: 1.2449 \t Val Loss: 3.7842\n",
      "\n",
      "result:  ['<தொட்ட்்்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 165 / 500] \t Loss: 1.2355 \t Val Loss: 3.7103\n",
      "\n",
      "result:  ['<தொட்ட்்்>்>  >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 166 / 500] \t Loss: 1.3430 \t Val Loss: 3.4573\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்>   ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 167 / 500] \t Loss: 1.3211 \t Val Loss: 3.6370\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 168 / 500] \t Loss: 1.2039 \t Val Loss: 3.4901\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 169 / 500] \t Loss: 1.2117 \t Val Loss: 4.0054\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 170 / 500] \t Loss: 1.2122 \t Val Loss: 3.5189\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 171 / 500] \t Loss: 1.2013 \t Val Loss: 3.6705\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்>> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 172 / 500] \t Loss: 1.2617 \t Val Loss: 3.6323\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 173 / 500] \t Loss: 1.1948 \t Val Loss: 3.8229\n",
      "\n",
      "result:  ['<தொட்டாச்்்்>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 174 / 500] \t Loss: 1.2250 \t Val Loss: 4.1601\n",
      "\n",
      "result:  ['<தொட்டாச்்்்்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 175 / 500] \t Loss: 1.1989 \t Val Loss: 3.6091\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 176 / 500] \t Loss: 1.1794 \t Val Loss: 4.0263\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 177 / 500] \t Loss: 1.2088 \t Val Loss: 3.5222\n",
      "\n",
      "result:  ['<தொட்டாச்்்்்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 178 / 500] \t Loss: 1.2447 \t Val Loss: 3.7311\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 179 / 500] \t Loss: 1.1846 \t Val Loss: 4.4004\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 180 / 500] \t Loss: 1.2026 \t Val Loss: 3.3396\n",
      "\n",
      "result:  ['<தொட்டாச்்்்்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 181 / 500] \t Loss: 1.2334 \t Val Loss: 3.7043\n",
      "\n",
      "result:  ['<தொட்டாச்்்>   ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 182 / 500] \t Loss: 1.2849 \t Val Loss: 3.7040\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 183 / 500] \t Loss: 1.1638 \t Val Loss: 3.5090\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 184 / 500] \t Loss: 1.1555 \t Val Loss: 3.8352\n",
      "\n",
      "result:  ['<தொட்ட்்>   ா >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 185 / 500] \t Loss: 1.3142 \t Val Loss: 3.7063\n",
      "\n",
      "result:  ['<தொட்ட்்்்> ்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 186 / 500] \t Loss: 1.2409 \t Val Loss: 3.5473\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்்>> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 187 / 500] \t Loss: 1.2272 \t Val Loss: 3.4422\n",
      "\n",
      "result:  ['<தொட்ட்ச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 188 / 500] \t Loss: 1.1479 \t Val Loss: 3.7488\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 189 / 500] \t Loss: 1.1666 \t Val Loss: 3.9073\n",
      "\n",
      "result:  ['<தொட்ட்்>   ா  ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 190 / 500] \t Loss: 1.3625 \t Val Loss: 4.1421\n",
      "\n",
      "result:  ['<தொட்ட்்> ்>   ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 191 / 500] \t Loss: 1.3509 \t Val Loss: 3.9230\n",
      "\n",
      "result:  ['<தொட்ட்்்்்>்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 192 / 500] \t Loss: 1.2044 \t Val Loss: 3.5457\n",
      "\n",
      "result:  ['<தொட்ட்்>> ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 193 / 500] \t Loss: 1.2493 \t Val Loss: 4.0006\n",
      "\n",
      "result:  ['<தொட்ட்்>>்>   ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 194 / 500] \t Loss: 1.3279 \t Val Loss: 4.0377\n",
      "\n",
      "result:  ['<தொட்ட்ச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 195 / 500] \t Loss: 1.1327 \t Val Loss: 3.8962\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 196 / 500] \t Loss: 1.1355 \t Val Loss: 3.4837\n",
      "\n",
      "result:  ['<தொட்ட்்்>  ா  ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 197 / 500] \t Loss: 1.3192 \t Val Loss: 3.6483\n",
      "\n",
      "result:  ['<தொட்ட்்்>்>  >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 198 / 500] \t Loss: 1.2679 \t Val Loss: 3.7326\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 199 / 500] \t Loss: 1.1330 \t Val Loss: 3.4737\n",
      "\n",
      "result:  ['<தொட்ட்்்>  ாச>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 200 / 500] \t Loss: 1.2762 \t Val Loss: 3.9731\n",
      "\n",
      "result:  ['<தொட்ட்்்்> ்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 201 / 500] \t Loss: 1.1918 \t Val Loss: 4.0833\n",
      "\n",
      "result:  ['<தொட்ட்ச்்>ா்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 202 / 500] \t Loss: 1.1776 \t Val Loss: 3.9825\n",
      "\n",
      "result:  ['<தொட்ட்ச்்>ா்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 203 / 500] \t Loss: 1.2341 \t Val Loss: 3.6107\n",
      "\n",
      "result:  ['<தொட்ட்ச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 204 / 500] \t Loss: 1.1064 \t Val Loss: 3.8302\n",
      "\n",
      "result:  ['<தொட்ட்்்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 205 / 500] \t Loss: 1.1134 \t Val Loss: 3.8896\n",
      "\n",
      "result:  ['<தொட்டாச்்>்> >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 206 / 500] \t Loss: 1.2353 \t Val Loss: 3.6997\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 207 / 500] \t Loss: 1.0970 \t Val Loss: 3.5916\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 208 / 500] \t Loss: 1.1540 \t Val Loss: 3.4667\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 209 / 500] \t Loss: 1.1398 \t Val Loss: 3.5033\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 210 / 500] \t Loss: 1.1471 \t Val Loss: 3.9226\n",
      "\n",
      "result:  ['<தொட்டாச்்>்்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 211 / 500] \t Loss: 1.1980 \t Val Loss: 3.7881\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 212 / 500] \t Loss: 1.0942 \t Val Loss: 4.0560\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 213 / 500] \t Loss: 1.1363 \t Val Loss: 3.5777\n",
      "\n",
      "result:  ['<தொட்டாச்்>்்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 214 / 500] \t Loss: 1.1397 \t Val Loss: 3.5897\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 215 / 500] \t Loss: 1.1217 \t Val Loss: 3.7493\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 216 / 500] \t Loss: 1.1256 \t Val Loss: 4.0182\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 217 / 500] \t Loss: 1.0812 \t Val Loss: 3.6071\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 218 / 500] \t Loss: 1.0855 \t Val Loss: 3.4441\n",
      "\n",
      "result:  ['<தொட்டாச்்>்்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 219 / 500] \t Loss: 1.1262 \t Val Loss: 3.9796\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 220 / 500] \t Loss: 1.0686 \t Val Loss: 3.9476\n",
      "\n",
      "result:  ['<தொட்டாச்்>்>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 221 / 500] \t Loss: 1.1986 \t Val Loss: 3.3704\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 222 / 500] \t Loss: 1.0745 \t Val Loss: 4.0505\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 223 / 500] \t Loss: 1.1044 \t Val Loss: 3.5411\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 224 / 500] \t Loss: 1.0972 \t Val Loss: 3.5565\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 225 / 500] \t Loss: 1.0855 \t Val Loss: 3.6771\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 226 / 500] \t Loss: 1.0943 \t Val Loss: 4.0033\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 227 / 500] \t Loss: 1.0387 \t Val Loss: 3.3824\n",
      "\n",
      "result:  ['<தொட்டாச்்>்> >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 228 / 500] \t Loss: 1.1794 \t Val Loss: 3.4116\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 229 / 500] \t Loss: 1.0337 \t Val Loss: 3.6939\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 230 / 500] \t Loss: 1.0877 \t Val Loss: 3.3898\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 231 / 500] \t Loss: 1.0850 \t Val Loss: 3.7861\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 232 / 500] \t Loss: 1.0370 \t Val Loss: 3.6570\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 233 / 500] \t Loss: 1.0752 \t Val Loss: 3.6271\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 234 / 500] \t Loss: 1.0413 \t Val Loss: 3.4878\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 235 / 500] \t Loss: 1.0181 \t Val Loss: 3.2936\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 236 / 500] \t Loss: 1.0303 \t Val Loss: 3.4550\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 237 / 500] \t Loss: 1.0278 \t Val Loss: 3.9034\n",
      "\n",
      "result:  ['<தொட்டாச்்>்>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 238 / 500] \t Loss: 1.1737 \t Val Loss: 3.5783\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 239 / 500] \t Loss: 1.0606 \t Val Loss: 3.5017\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 240 / 500] \t Loss: 1.0614 \t Val Loss: 3.6221\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 241 / 500] \t Loss: 1.0099 \t Val Loss: 3.5449\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 242 / 500] \t Loss: 1.0206 \t Val Loss: 3.7229\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 243 / 500] \t Loss: 1.0819 \t Val Loss: 3.7787\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 244 / 500] \t Loss: 1.0104 \t Val Loss: 3.3789\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 245 / 500] \t Loss: 1.0083 \t Val Loss: 3.4213\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 246 / 500] \t Loss: 1.0036 \t Val Loss: 3.9217\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 247 / 500] \t Loss: 1.0391 \t Val Loss: 3.3620\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 248 / 500] \t Loss: 1.0064 \t Val Loss: 3.2781\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 249 / 500] \t Loss: 0.9990 \t Val Loss: 3.8911\n",
      "\n",
      "result:  ['<தொட்டாச்்>்்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 250 / 500] \t Loss: 1.0886 \t Val Loss: 3.8263\n",
      "\n",
      "result:  ['<தொட்டாச்்>்்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 251 / 500] \t Loss: 1.0845 \t Val Loss: 3.3802\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 252 / 500] \t Loss: 1.0225 \t Val Loss: 3.5483\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 253 / 500] \t Loss: 1.0245 \t Val Loss: 3.3023\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 254 / 500] \t Loss: 1.0573 \t Val Loss: 3.5186\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 255 / 500] \t Loss: 0.9709 \t Val Loss: 3.4224\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 256 / 500] \t Loss: 1.0098 \t Val Loss: 3.5600\n",
      "\n",
      "result:  ['<தொட்டாச்்>   >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 257 / 500] \t Loss: 1.1450 \t Val Loss: 3.5882\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 258 / 500] \t Loss: 1.0008 \t Val Loss: 3.5925\n",
      "\n",
      "result:  ['<தொட்டாச்்> ்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 259 / 500] \t Loss: 1.0298 \t Val Loss: 3.4439\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 260 / 500] \t Loss: 0.9862 \t Val Loss: 3.8224\n",
      "\n",
      "result:  ['<தொட்டாச்்> ்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 261 / 500] \t Loss: 1.0399 \t Val Loss: 3.6469\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 262 / 500] \t Loss: 0.9774 \t Val Loss: 3.4105\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 263 / 500] \t Loss: 0.9584 \t Val Loss: 3.5254\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 264 / 500] \t Loss: 1.0002 \t Val Loss: 3.4793\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 265 / 500] \t Loss: 0.9946 \t Val Loss: 3.6976\n",
      "\n",
      "result:  ['<தொட்டாச்்்>   ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 266 / 500] \t Loss: 1.1477 \t Val Loss: 3.8941\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 267 / 500] \t Loss: 0.9476 \t Val Loss: 3.3953\n",
      "\n",
      "result:  ['<தொட்டாச்்்>   ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 268 / 500] \t Loss: 1.1419 \t Val Loss: 3.2860\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>ச', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 269 / 500] \t Loss: 0.9741 \t Val Loss: 3.7555\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 270 / 500] \t Loss: 0.9697 \t Val Loss: 3.2856\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 271 / 500] \t Loss: 0.9979 \t Val Loss: 3.5140\n",
      "\n",
      "result:  ['<தொட்டாச்்>> >>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 272 / 500] \t Loss: 1.0721 \t Val Loss: 3.7407\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>ச', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 273 / 500] \t Loss: 0.9649 \t Val Loss: 4.0783\n",
      "\n",
      "result:  ['<தொட்டாச்்்>> >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 274 / 500] \t Loss: 1.0292 \t Val Loss: 4.1449\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 275 / 500] \t Loss: 0.9885 \t Val Loss: 3.3805\n",
      "\n",
      "result:  ['<தொட்டாச்்>> > ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 276 / 500] \t Loss: 1.0661 \t Val Loss: 3.4113\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 277 / 500] \t Loss: 0.9822 \t Val Loss: 3.8738\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 278 / 500] \t Loss: 0.9962 \t Val Loss: 3.6270\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 279 / 500] \t Loss: 0.9760 \t Val Loss: 3.6187\n",
      "\n",
      "result:  ['<தொட்டாச்்>>  >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 280 / 500] \t Loss: 1.0961 \t Val Loss: 3.4013\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>ச', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 281 / 500] \t Loss: 0.9571 \t Val Loss: 3.3594\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 282 / 500] \t Loss: 0.9254 \t Val Loss: 3.3612\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 283 / 500] \t Loss: 0.9850 \t Val Loss: 4.2565\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 284 / 500] \t Loss: 0.9595 \t Val Loss: 3.7458\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 285 / 500] \t Loss: 0.9199 \t Val Loss: 3.3204\n",
      "\n",
      "result:  ['<தொட்டாச்்்>ச>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 286 / 500] \t Loss: 0.9812 \t Val Loss: 3.6031\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 287 / 500] \t Loss: 0.9120 \t Val Loss: 3.5425\n",
      "\n",
      "result:  ['<தொட்டாச்்்>ச்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 288 / 500] \t Loss: 1.0127 \t Val Loss: 3.6417\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 289 / 500] \t Loss: 0.9396 \t Val Loss: 3.5340\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 290 / 500] \t Loss: 0.9400 \t Val Loss: 3.5417\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 291 / 500] \t Loss: 0.9212 \t Val Loss: 3.8598\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 292 / 500] \t Loss: 0.9237 \t Val Loss: 4.0887\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 293 / 500] \t Loss: 0.9310 \t Val Loss: 3.5519\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 294 / 500] \t Loss: 0.9315 \t Val Loss: 3.5013\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 295 / 500] \t Loss: 0.9450 \t Val Loss: 3.6780\n",
      "\n",
      "result:  ['<தொட்டாச்்்>ச்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 296 / 500] \t Loss: 0.9951 \t Val Loss: 3.7572\n",
      "\n",
      "result:  ['<தொட்டாச்்்>ச்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 297 / 500] \t Loss: 0.9922 \t Val Loss: 4.1388\n",
      "\n",
      "result:  ['<தொட்டாச்்>>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 298 / 500] \t Loss: 0.9417 \t Val Loss: 3.6034\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 299 / 500] \t Loss: 0.9118 \t Val Loss: 3.4326\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 300 / 500] \t Loss: 0.8929 \t Val Loss: 3.8899\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 301 / 500] \t Loss: 0.9356 \t Val Loss: 3.9589\n",
      "\n",
      "result:  ['<தொட்டாச்்்>ச>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 302 / 500] \t Loss: 0.9638 \t Val Loss: 3.5260\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 303 / 500] \t Loss: 0.9117 \t Val Loss: 3.4292\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 304 / 500] \t Loss: 0.8942 \t Val Loss: 4.1857\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 305 / 500] \t Loss: 0.8914 \t Val Loss: 3.9158\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 306 / 500] \t Loss: 0.8902 \t Val Loss: 3.6056\n",
      "\n",
      "result:  ['<தொட்டாச்்்>ச்>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 307 / 500] \t Loss: 0.9630 \t Val Loss: 3.6818\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>ச', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 308 / 500] \t Loss: 0.9172 \t Val Loss: 3.8366\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 309 / 500] \t Loss: 0.9037 \t Val Loss: 3.5056\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 310 / 500] \t Loss: 0.9377 \t Val Loss: 3.5878\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்>ச', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 311 / 500] \t Loss: 0.9071 \t Val Loss: 3.4088\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 312 / 500] \t Loss: 0.9139 \t Val Loss: 3.5259\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 313 / 500] \t Loss: 0.8772 \t Val Loss: 3.9046\n",
      "\n",
      "result:  ['<தொட்டாச்்்ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 314 / 500] \t Loss: 0.8854 \t Val Loss: 3.8625\n",
      "\n",
      "result:  ['<தொட்டாச்்>ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 315 / 500] \t Loss: 0.9246 \t Val Loss: 3.5585\n",
      "\n",
      "result:  ['<தொட்டாச்்்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 316 / 500] \t Loss: 0.8812 \t Val Loss: 3.3466\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 317 / 500] \t Loss: 0.8586 \t Val Loss: 3.5435\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 318 / 500] \t Loss: 0.8878 \t Val Loss: 3.9503\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 319 / 500] \t Loss: 0.9504 \t Val Loss: 3.5633\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 320 / 500] \t Loss: 0.8513 \t Val Loss: 3.5595\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 321 / 500] \t Loss: 0.9462 \t Val Loss: 3.6441\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>> >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 322 / 500] \t Loss: 0.9496 \t Val Loss: 3.4161\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>> >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 323 / 500] \t Loss: 0.9466 \t Val Loss: 3.3819\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 324 / 500] \t Loss: 0.8637 \t Val Loss: 4.0097\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 325 / 500] \t Loss: 0.8622 \t Val Loss: 3.8395\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 326 / 500] \t Loss: 0.8418 \t Val Loss: 4.0376\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>> >', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 327 / 500] \t Loss: 0.9348 \t Val Loss: 3.6711\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 328 / 500] \t Loss: 0.8704 \t Val Loss: 3.9020\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 329 / 500] \t Loss: 0.8555 \t Val Loss: 3.7095\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 330 / 500] \t Loss: 0.8674 \t Val Loss: 3.7901\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 331 / 500] \t Loss: 0.8658 \t Val Loss: 3.6545\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>>  ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 332 / 500] \t Loss: 0.9910 \t Val Loss: 3.6340\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 333 / 500] \t Loss: 0.8313 \t Val Loss: 3.9337\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 334 / 500] \t Loss: 0.9058 \t Val Loss: 3.6623\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 335 / 500] \t Loss: 0.8597 \t Val Loss: 3.9358\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 336 / 500] \t Loss: 0.8582 \t Val Loss: 3.5780\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 337 / 500] \t Loss: 0.8508 \t Val Loss: 3.6967\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 338 / 500] \t Loss: 0.8243 \t Val Loss: 4.1576\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>ா>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 339 / 500] \t Loss: 0.8921 \t Val Loss: 3.7393\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 340 / 500] \t Loss: 0.8413 \t Val Loss: 4.1492\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 341 / 500] \t Loss: 0.8400 \t Val Loss: 4.1254\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 342 / 500] \t Loss: 0.8379 \t Val Loss: 3.7865\n",
      "\n",
      "result:  ['<தொட்டாச்ச்>ாச்', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 343 / 500] \t Loss: 0.9734 \t Val Loss: 3.4270\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 344 / 500] \t Loss: 0.8170 \t Val Loss: 3.6182\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 345 / 500] \t Loss: 0.8828 \t Val Loss: 3.4755\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 346 / 500] \t Loss: 0.8373 \t Val Loss: 3.4985\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 347 / 500] \t Loss: 0.8417 \t Val Loss: 3.8146\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 348 / 500] \t Loss: 0.8335 \t Val Loss: 4.2293\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 349 / 500] \t Loss: 0.8236 \t Val Loss: 3.6678\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 350 / 500] \t Loss: 0.8297 \t Val Loss: 3.6742\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 351 / 500] \t Loss: 0.8035 \t Val Loss: 3.7186\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 352 / 500] \t Loss: 0.8035 \t Val Loss: 3.4199\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 353 / 500] \t Loss: 0.8169 \t Val Loss: 3.7675\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 354 / 500] \t Loss: 0.8308 \t Val Loss: 3.5825\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 355 / 500] \t Loss: 0.8788 \t Val Loss: 3.7990\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 356 / 500] \t Loss: 0.9050 \t Val Loss: 4.2055\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 357 / 500] \t Loss: 0.8091 \t Val Loss: 3.8602\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 358 / 500] \t Loss: 0.7958 \t Val Loss: 3.5984\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 359 / 500] \t Loss: 0.8152 \t Val Loss: 3.7085\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 360 / 500] \t Loss: 0.8029 \t Val Loss: 3.7337\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 361 / 500] \t Loss: 0.8679 \t Val Loss: 4.1702\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 362 / 500] \t Loss: 0.8110 \t Val Loss: 3.8996\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 363 / 500] \t Loss: 0.7969 \t Val Loss: 3.6111\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 364 / 500] \t Loss: 0.8083 \t Val Loss: 3.9982\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 365 / 500] \t Loss: 0.7933 \t Val Loss: 4.2098\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 366 / 500] \t Loss: 0.7855 \t Val Loss: 3.6248\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 367 / 500] \t Loss: 0.7839 \t Val Loss: 3.7473\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 368 / 500] \t Loss: 0.8456 \t Val Loss: 3.9898\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 369 / 500] \t Loss: 0.7804 \t Val Loss: 3.7585\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 370 / 500] \t Loss: 0.7868 \t Val Loss: 4.1745\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 371 / 500] \t Loss: 0.7975 \t Val Loss: 3.6632\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 372 / 500] \t Loss: 0.7709 \t Val Loss: 3.7949\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 373 / 500] \t Loss: 0.7695 \t Val Loss: 3.4190\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 374 / 500] \t Loss: 0.8359 \t Val Loss: 3.7934\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 375 / 500] \t Loss: 0.7709 \t Val Loss: 4.5036\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 376 / 500] \t Loss: 0.7694 \t Val Loss: 3.5532\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 377 / 500] \t Loss: 0.7678 \t Val Loss: 3.7688\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 378 / 500] \t Loss: 0.7624 \t Val Loss: 3.8366\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 379 / 500] \t Loss: 0.7647 \t Val Loss: 3.6357\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 380 / 500] \t Loss: 0.7630 \t Val Loss: 3.4592\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 381 / 500] \t Loss: 0.7753 \t Val Loss: 3.4328\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 382 / 500] \t Loss: 0.7562 \t Val Loss: 3.7721\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 383 / 500] \t Loss: 0.8340 \t Val Loss: 3.6434\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 384 / 500] \t Loss: 0.8375 \t Val Loss: 3.6803\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 385 / 500] \t Loss: 0.8363 \t Val Loss: 3.4990\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 386 / 500] \t Loss: 0.8200 \t Val Loss: 3.8313\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 387 / 500] \t Loss: 0.7535 \t Val Loss: 3.5641\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 388 / 500] \t Loss: 0.7522 \t Val Loss: 3.3810\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 389 / 500] \t Loss: 0.7802 \t Val Loss: 4.2528\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 390 / 500] \t Loss: 0.7449 \t Val Loss: 4.0736\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 391 / 500] \t Loss: 0.8239 \t Val Loss: 3.5613\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 392 / 500] \t Loss: 0.7468 \t Val Loss: 3.8042\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 393 / 500] \t Loss: 0.7749 \t Val Loss: 3.8166\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 394 / 500] \t Loss: 0.7642 \t Val Loss: 4.0309\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 395 / 500] \t Loss: 0.7427 \t Val Loss: 3.7177\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 396 / 500] \t Loss: 0.7381 \t Val Loss: 3.4710\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 397 / 500] \t Loss: 0.8557 \t Val Loss: 3.5161\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 398 / 500] \t Loss: 0.7554 \t Val Loss: 4.2071\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 399 / 500] \t Loss: 0.7669 \t Val Loss: 3.8042\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 400 / 500] \t Loss: 0.7369 \t Val Loss: 3.6003\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 401 / 500] \t Loss: 0.7551 \t Val Loss: 3.6775\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 402 / 500] \t Loss: 0.7538 \t Val Loss: 3.7268\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 403 / 500] \t Loss: 0.8087 \t Val Loss: 3.5073\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 404 / 500] \t Loss: 0.7600 \t Val Loss: 3.4236\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 405 / 500] \t Loss: 0.8066 \t Val Loss: 3.7396\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 406 / 500] \t Loss: 0.8033 \t Val Loss: 4.3376\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 407 / 500] \t Loss: 0.7293 \t Val Loss: 3.9927\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 408 / 500] \t Loss: 0.7281 \t Val Loss: 3.4295\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 409 / 500] \t Loss: 0.7268 \t Val Loss: 3.5885\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 410 / 500] \t Loss: 0.7941 \t Val Loss: 3.9227\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 411 / 500] \t Loss: 0.7377 \t Val Loss: 3.3998\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 412 / 500] \t Loss: 0.7360 \t Val Loss: 3.4940\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 413 / 500] \t Loss: 0.7414 \t Val Loss: 3.6654\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 414 / 500] \t Loss: 0.7470 \t Val Loss: 3.7458\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 415 / 500] \t Loss: 0.7848 \t Val Loss: 4.2621\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 416 / 500] \t Loss: 0.7444 \t Val Loss: 3.9361\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 417 / 500] \t Loss: 0.7182 \t Val Loss: 3.6725\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 418 / 500] \t Loss: 0.7938 \t Val Loss: 3.9974\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 419 / 500] \t Loss: 0.7160 \t Val Loss: 3.7180\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 420 / 500] \t Loss: 0.7149 \t Val Loss: 3.7437\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 421 / 500] \t Loss: 0.7087 \t Val Loss: 3.7535\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 422 / 500] \t Loss: 0.7726 \t Val Loss: 4.3801\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 423 / 500] \t Loss: 0.7114 \t Val Loss: 3.8074\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 424 / 500] \t Loss: 0.7822 \t Val Loss: 4.0733\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 425 / 500] \t Loss: 0.7757 \t Val Loss: 3.6148\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 426 / 500] \t Loss: 0.7665 \t Val Loss: 3.5903\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 427 / 500] \t Loss: 0.7073 \t Val Loss: 3.9318\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 428 / 500] \t Loss: 0.7758 \t Val Loss: 3.6626\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 429 / 500] \t Loss: 0.7007 \t Val Loss: 3.6397\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 430 / 500] \t Loss: 0.6994 \t Val Loss: 3.8902\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 431 / 500] \t Loss: 0.7693 \t Val Loss: 3.9567\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 432 / 500] \t Loss: 0.6961 \t Val Loss: 3.7615\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 433 / 500] \t Loss: 0.6945 \t Val Loss: 3.7649\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 434 / 500] \t Loss: 0.7098 \t Val Loss: 3.9980\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 435 / 500] \t Loss: 0.7009 \t Val Loss: 3.9849\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 436 / 500] \t Loss: 0.7005 \t Val Loss: 3.6564\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 437 / 500] \t Loss: 0.6996 \t Val Loss: 3.8164\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 438 / 500] \t Loss: 0.6877 \t Val Loss: 3.8350\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 439 / 500] \t Loss: 0.6865 \t Val Loss: 3.9702\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 440 / 500] \t Loss: 0.6853 \t Val Loss: 3.4776\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 441 / 500] \t Loss: 0.6839 \t Val Loss: 3.8892\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 442 / 500] \t Loss: 0.6826 \t Val Loss: 3.7321\n",
      "\n",
      "result:  ['<தொட்டாச்சாசாய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 443 / 500] \t Loss: 0.6920 \t Val Loss: 3.7379\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 444 / 500] \t Loss: 0.6961 \t Val Loss: 4.0284\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 445 / 500] \t Loss: 0.6893 \t Val Loss: 3.7062\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 446 / 500] \t Loss: 0.6877 \t Val Loss: 3.8709\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 447 / 500] \t Loss: 0.6934 \t Val Loss: 4.2764\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 448 / 500] \t Loss: 0.6752 \t Val Loss: 3.9674\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 449 / 500] \t Loss: 0.6831 \t Val Loss: 3.5463\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 450 / 500] \t Loss: 0.6905 \t Val Loss: 3.9716\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 451 / 500] \t Loss: 0.6806 \t Val Loss: 3.4723\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 452 / 500] \t Loss: 0.6708 \t Val Loss: 3.5032\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 453 / 500] \t Loss: 0.6781 \t Val Loss: 3.7089\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 454 / 500] \t Loss: 0.6959 \t Val Loss: 3.5711\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 455 / 500] \t Loss: 0.7467 \t Val Loss: 4.1280\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 456 / 500] \t Loss: 0.6847 \t Val Loss: 3.8865\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 457 / 500] \t Loss: 0.6731 \t Val Loss: 3.6680\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 458 / 500] \t Loss: 0.6720 \t Val Loss: 4.2307\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 459 / 500] \t Loss: 0.6997 \t Val Loss: 3.8603\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 460 / 500] \t Loss: 0.6628 \t Val Loss: 4.1140\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 461 / 500] \t Loss: 0.6685 \t Val Loss: 4.1198\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 462 / 500] \t Loss: 0.7370 \t Val Loss: 4.3018\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 463 / 500] \t Loss: 0.7501 \t Val Loss: 3.6522\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 464 / 500] \t Loss: 0.6653 \t Val Loss: 4.1163\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 465 / 500] \t Loss: 0.6582 \t Val Loss: 3.8179\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 466 / 500] \t Loss: 0.6825 \t Val Loss: 4.2577\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 467 / 500] \t Loss: 0.6812 \t Val Loss: 3.4660\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 468 / 500] \t Loss: 0.6553 \t Val Loss: 3.6557\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 469 / 500] \t Loss: 0.6608 \t Val Loss: 4.1184\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 470 / 500] \t Loss: 0.6599 \t Val Loss: 3.4880\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 471 / 500] \t Loss: 0.6874 \t Val Loss: 3.7576\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 472 / 500] \t Loss: 0.6753 \t Val Loss: 4.1179\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 473 / 500] \t Loss: 0.6569 \t Val Loss: 4.1651\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 474 / 500] \t Loss: 0.6846 \t Val Loss: 3.7605\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>> ', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 475 / 500] \t Loss: 0.7694 \t Val Loss: 4.0647\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 476 / 500] \t Loss: 0.6708 \t Val Loss: 3.5935\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 477 / 500] \t Loss: 0.6532 \t Val Loss: 3.6888\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 478 / 500] \t Loss: 0.6685 \t Val Loss: 3.7312\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய்>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 479 / 500] \t Loss: 0.6674 \t Val Loss: 4.3966\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 480 / 500] \t Loss: 0.7276 \t Val Loss: 3.8811\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 481 / 500] \t Loss: 0.6441 \t Val Loss: 4.2669\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 482 / 500] \t Loss: 0.6430 \t Val Loss: 3.9506\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 483 / 500] \t Loss: 0.6484 \t Val Loss: 3.6262\n",
      "\n",
      "result:  ['<தொட்டாச்ச்ய>>>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 484 / 500] \t Loss: 0.7359 \t Val Loss: 3.9171\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 485 / 500] \t Loss: 0.6470 \t Val Loss: 4.4302\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 486 / 500] \t Loss: 0.6383 \t Val Loss: 3.6777\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 487 / 500] \t Loss: 0.6454 \t Val Loss: 3.9187\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 488 / 500] \t Loss: 0.6362 \t Val Loss: 3.9230\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 489 / 500] \t Loss: 0.6350 \t Val Loss: 3.7247\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 490 / 500] \t Loss: 0.6432 \t Val Loss: 4.0725\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 491 / 500] \t Loss: 0.6424 \t Val Loss: 4.1791\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 492 / 500] \t Loss: 0.6412 \t Val Loss: 3.6102\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 493 / 500] \t Loss: 0.6312 \t Val Loss: 3.5566\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 494 / 500] \t Loss: 0.6303 \t Val Loss: 3.7875\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 495 / 500] \t Loss: 0.6293 \t Val Loss: 3.5000\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 496 / 500] \t Loss: 0.6370 \t Val Loss: 3.5711\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 497 / 500] \t Loss: 0.6271 \t Val Loss: 3.8177\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 498 / 500] \t Loss: 0.6260 \t Val Loss: 3.7770\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 499 / 500] \t Loss: 0.6247 \t Val Loss: 3.9025\n",
      "\n",
      "result:  ['<தொட்டாச்சாச்ய>', '<மென்மைதான்>   ']\n",
      "target:  ['<தொட்டாச்சார்ய>', '<மென்மைதான்>   ']\n",
      "[Epoch 500 / 500] \t Loss: 0.6234 \t Val Loss: 3.9765\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25fbb7efa90>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    no_of_batch = 0\n",
    "    for i in range(0, len(train_source[:2]), batch_size):\n",
    "        src_strings = train_source[i: i+batch_size]\n",
    "        tar_strings = train_target[i: i+batch_size]\n",
    "\n",
    "        src_strings = preprocess(src_strings, start_token, end_token, pad_token)\n",
    "        tar_strings = preprocess(tar_strings, start_token, end_token, pad_token)\n",
    "\n",
    "        #transposing to make the shape as expected\n",
    "        inp_data = string_to_tensor(src_strings, en_l2i).transpose(0,1)\n",
    "        target = string_to_tensor(tar_strings, tr_l2i).transpose(0,1)\n",
    "\n",
    "\n",
    "        output = mod(inp_data, target)\n",
    "        # print(\"train: output : \", output.shape)\n",
    "        # result = temp_print(output.argmax(2))\n",
    "        # print(\"result: \", result)\n",
    "        # print(\"target: \", tar_strings)\n",
    "        \n",
    "        # print(\"output: \",result)\n",
    "        # print(\"target:\", tar_strings)\n",
    "\n",
    "        # print(\"op before reshopsed \", output.shape)\n",
    "        # print(\"tar before reshape: \", target.shape)\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target.reshape(-1)\n",
    "\n",
    "        # print(\"op: \", output.shape)\n",
    "        # print(\"tar: \", target.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(mod.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        no_of_batch += 1        \n",
    "\n",
    "    # val_output = mod(val_source_tensor, val_target_tensor)\n",
    "    # val_output = val_output.reshape(-1, val_output.shape[2])\n",
    "    # val_target_tensor = val_target_tensor.reshape(-1)\n",
    "    # # print(f\"val output : {val_output.shape} \\t val_target: {val_target_tensor.shape}\")\n",
    "    # val_loss = criterion(val_output, val_target_tensor)\n",
    "\n",
    "    val_loss= mod.calc_evaluation_loss(val_source[:2], val_target[:2])\n",
    "    # val_loss = 0\n",
    "    \n",
    "    print(f\"[Epoch {epoch+1:3d} / {num_epochs}] \\t Loss: {(running_loss/no_of_batch):.4f} \\t Val Loss: {val_loss:2.4f}\")\n",
    "    print()\n",
    "    loss_list.append(running_loss/no_of_batch)\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
